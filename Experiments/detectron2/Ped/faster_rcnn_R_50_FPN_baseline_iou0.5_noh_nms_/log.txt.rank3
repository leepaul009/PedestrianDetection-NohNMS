[08/06 07:30:46] detectron2 INFO: Rank of current process: 3. World size: 4
[08/06 07:30:47] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 07:30:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 07:30:47] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 07:30:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 07:30:48] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 07:30:50] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 07:30:50] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 07:30:50] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 07:30:51] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 07:30:51] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 07:30:52] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 07:30:52] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 07:30:52] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 07:30:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from datasets/noh_nms_model_final.pth ...
[08/06 07:30:53] detectron2.engine.train_loop INFO: Starting training from iteration 20000
[08/06 07:34:29] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:34:29] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:34:29] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:34:29] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:34:29] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 07:34:37] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0668 s / img. ETA=0:02:34
[08/06 07:34:42] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0671 s / img. ETA=0:02:30
[08/06 07:34:47] detectron2.evaluation.evaluator INFO: Inference done 158/2290. 0.0673 s / img. ETA=0:02:26
[08/06 07:34:52] detectron2.evaluation.evaluator INFO: Inference done 229/2290. 0.0680 s / img. ETA=0:02:22
[08/06 07:34:57] detectron2.evaluation.evaluator INFO: Inference done 302/2290. 0.0678 s / img. ETA=0:02:17
[08/06 07:35:02] detectron2.evaluation.evaluator INFO: Inference done 373/2290. 0.0681 s / img. ETA=0:02:13
[08/06 07:35:07] detectron2.evaluation.evaluator INFO: Inference done 441/2290. 0.0688 s / img. ETA=0:02:09
[08/06 07:35:12] detectron2.evaluation.evaluator INFO: Inference done 512/2290. 0.0689 s / img. ETA=0:02:04
[08/06 07:35:17] detectron2.evaluation.evaluator INFO: Inference done 584/2290. 0.0689 s / img. ETA=0:01:59
[08/06 07:35:22] detectron2.evaluation.evaluator INFO: Inference done 655/2290. 0.0689 s / img. ETA=0:01:54
[08/06 07:35:27] detectron2.evaluation.evaluator INFO: Inference done 723/2290. 0.0692 s / img. ETA=0:01:50
[08/06 07:35:32] detectron2.evaluation.evaluator INFO: Inference done 793/2290. 0.0694 s / img. ETA=0:01:45
[08/06 07:35:37] detectron2.evaluation.evaluator INFO: Inference done 862/2290. 0.0696 s / img. ETA=0:01:41
[08/06 07:35:42] detectron2.evaluation.evaluator INFO: Inference done 931/2290. 0.0697 s / img. ETA=0:01:36
[08/06 07:35:47] detectron2.evaluation.evaluator INFO: Inference done 1002/2290. 0.0697 s / img. ETA=0:01:31
[08/06 07:35:52] detectron2.evaluation.evaluator INFO: Inference done 1072/2290. 0.0698 s / img. ETA=0:01:26
[08/06 07:35:57] detectron2.evaluation.evaluator INFO: Inference done 1141/2290. 0.0699 s / img. ETA=0:01:21
[08/06 07:36:02] detectron2.evaluation.evaluator INFO: Inference done 1210/2290. 0.0700 s / img. ETA=0:01:17
[08/06 07:36:07] detectron2.evaluation.evaluator INFO: Inference done 1280/2290. 0.0700 s / img. ETA=0:01:12
[08/06 07:36:12] detectron2.evaluation.evaluator INFO: Inference done 1351/2290. 0.0700 s / img. ETA=0:01:06
[08/06 07:36:17] detectron2.evaluation.evaluator INFO: Inference done 1420/2290. 0.0700 s / img. ETA=0:01:02
[08/06 07:36:22] detectron2.evaluation.evaluator INFO: Inference done 1490/2290. 0.0700 s / img. ETA=0:00:57
[08/06 07:36:27] detectron2.evaluation.evaluator INFO: Inference done 1560/2290. 0.0701 s / img. ETA=0:00:52
[08/06 07:36:33] detectron2.evaluation.evaluator INFO: Inference done 1631/2290. 0.0701 s / img. ETA=0:00:47
[08/06 07:36:38] detectron2.evaluation.evaluator INFO: Inference done 1702/2290. 0.0701 s / img. ETA=0:00:41
[08/06 07:36:43] detectron2.evaluation.evaluator INFO: Inference done 1774/2290. 0.0700 s / img. ETA=0:00:36
[08/06 07:36:48] detectron2.evaluation.evaluator INFO: Inference done 1845/2290. 0.0700 s / img. ETA=0:00:31
[08/06 07:36:53] detectron2.evaluation.evaluator INFO: Inference done 1915/2290. 0.0700 s / img. ETA=0:00:26
[08/06 07:36:58] detectron2.evaluation.evaluator INFO: Inference done 1986/2290. 0.0700 s / img. ETA=0:00:21
[08/06 07:37:03] detectron2.evaluation.evaluator INFO: Inference done 2055/2290. 0.0700 s / img. ETA=0:00:16
[08/06 07:37:08] detectron2.evaluation.evaluator INFO: Inference done 2123/2290. 0.0701 s / img. ETA=0:00:11
[08/06 07:37:13] detectron2.evaluation.evaluator INFO: Inference done 2194/2290. 0.0701 s / img. ETA=0:00:06
[08/06 07:37:18] detectron2.evaluation.evaluator INFO: Inference done 2265/2290. 0.0701 s / img. ETA=0:00:01
[08/06 07:37:20] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:43.501360 (0.071554 s / img per device, on 4 devices)
[08/06 07:37:20] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:40 (0.070092 s / img per device, on 4 devices)
[08/06 07:40:53] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:40:53] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:40:54] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:40:54] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:40:54] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 07:41:01] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0671 s / img. ETA=0:02:35
[08/06 07:41:06] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0672 s / img. ETA=0:02:30
[08/06 07:41:11] detectron2.evaluation.evaluator INFO: Inference done 158/2290. 0.0673 s / img. ETA=0:02:26
[08/06 07:41:16] detectron2.evaluation.evaluator INFO: Inference done 231/2290. 0.0675 s / img. ETA=0:02:21
[08/06 07:41:21] detectron2.evaluation.evaluator INFO: Inference done 302/2290. 0.0679 s / img. ETA=0:02:17
[08/06 07:41:26] detectron2.evaluation.evaluator INFO: Inference done 374/2290. 0.0681 s / img. ETA=0:02:13
[08/06 07:41:31] detectron2.evaluation.evaluator INFO: Inference done 444/2290. 0.0685 s / img. ETA=0:02:08
[08/06 07:41:36] detectron2.evaluation.evaluator INFO: Inference done 514/2290. 0.0688 s / img. ETA=0:02:04
[08/06 07:41:41] detectron2.evaluation.evaluator INFO: Inference done 586/2290. 0.0688 s / img. ETA=0:01:59
[08/06 07:41:46] detectron2.evaluation.evaluator INFO: Inference done 655/2290. 0.0692 s / img. ETA=0:01:55
[08/06 07:41:51] detectron2.evaluation.evaluator INFO: Inference done 725/2290. 0.0693 s / img. ETA=0:01:50
[08/06 07:41:57] detectron2.evaluation.evaluator INFO: Inference done 795/2290. 0.0695 s / img. ETA=0:01:45
[08/06 07:42:02] detectron2.evaluation.evaluator INFO: Inference done 867/2290. 0.0694 s / img. ETA=0:01:40
[08/06 07:42:07] detectron2.evaluation.evaluator INFO: Inference done 938/2290. 0.0694 s / img. ETA=0:01:35
[08/06 07:42:12] detectron2.evaluation.evaluator INFO: Inference done 1009/2290. 0.0695 s / img. ETA=0:01:30
[08/06 07:42:17] detectron2.evaluation.evaluator INFO: Inference done 1080/2290. 0.0695 s / img. ETA=0:01:25
[08/06 07:42:22] detectron2.evaluation.evaluator INFO: Inference done 1152/2290. 0.0695 s / img. ETA=0:01:20
[08/06 07:42:27] detectron2.evaluation.evaluator INFO: Inference done 1223/2290. 0.0694 s / img. ETA=0:01:15
[08/06 07:42:32] detectron2.evaluation.evaluator INFO: Inference done 1292/2290. 0.0696 s / img. ETA=0:01:10
[08/06 07:42:37] detectron2.evaluation.evaluator INFO: Inference done 1361/2290. 0.0697 s / img. ETA=0:01:05
[08/06 07:42:42] detectron2.evaluation.evaluator INFO: Inference done 1431/2290. 0.0697 s / img. ETA=0:01:01
[08/06 07:42:47] detectron2.evaluation.evaluator INFO: Inference done 1500/2290. 0.0698 s / img. ETA=0:00:56
[08/06 07:42:52] detectron2.evaluation.evaluator INFO: Inference done 1570/2290. 0.0698 s / img. ETA=0:00:51
[08/06 07:42:57] detectron2.evaluation.evaluator INFO: Inference done 1640/2290. 0.0699 s / img. ETA=0:00:46
[08/06 07:43:02] detectron2.evaluation.evaluator INFO: Inference done 1711/2290. 0.0698 s / img. ETA=0:00:41
[08/06 07:43:07] detectron2.evaluation.evaluator INFO: Inference done 1781/2290. 0.0699 s / img. ETA=0:00:36
[08/06 07:43:12] detectron2.evaluation.evaluator INFO: Inference done 1853/2290. 0.0698 s / img. ETA=0:00:31
[08/06 07:43:17] detectron2.evaluation.evaluator INFO: Inference done 1924/2290. 0.0698 s / img. ETA=0:00:26
[08/06 07:43:22] detectron2.evaluation.evaluator INFO: Inference done 1993/2290. 0.0699 s / img. ETA=0:00:21
[08/06 07:43:27] detectron2.evaluation.evaluator INFO: Inference done 2063/2290. 0.0699 s / img. ETA=0:00:16
[08/06 07:43:32] detectron2.evaluation.evaluator INFO: Inference done 2135/2290. 0.0699 s / img. ETA=0:00:11
[08/06 07:43:37] detectron2.evaluation.evaluator INFO: Inference done 2205/2290. 0.0699 s / img. ETA=0:00:06
[08/06 07:43:42] detectron2.evaluation.evaluator INFO: Inference done 2277/2290. 0.0698 s / img. ETA=0:00:00
[08/06 07:43:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:42.764975 (0.071232 s / img per device, on 4 devices)
[08/06 07:43:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:39 (0.069824 s / img per device, on 4 devices)
[08/06 07:47:16] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:47:16] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:47:17] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:47:17] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:47:17] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 07:47:24] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0666 s / img. ETA=0:02:33
[08/06 07:47:29] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0671 s / img. ETA=0:02:30
[08/06 07:47:34] detectron2.evaluation.evaluator INFO: Inference done 158/2290. 0.0672 s / img. ETA=0:02:25
[08/06 07:47:39] detectron2.evaluation.evaluator INFO: Inference done 231/2290. 0.0673 s / img. ETA=0:02:21
[08/06 07:47:44] detectron2.evaluation.evaluator INFO: Inference done 304/2290. 0.0674 s / img. ETA=0:02:16
[08/06 07:47:49] detectron2.evaluation.evaluator INFO: Inference done 377/2290. 0.0674 s / img. ETA=0:02:11
[08/06 07:47:54] detectron2.evaluation.evaluator INFO: Inference done 446/2290. 0.0680 s / img. ETA=0:02:07
[08/06 07:47:59] detectron2.evaluation.evaluator INFO: Inference done 517/2290. 0.0683 s / img. ETA=0:02:03
[08/06 07:48:04] detectron2.evaluation.evaluator INFO: Inference done 588/2290. 0.0685 s / img. ETA=0:01:58
[08/06 07:48:09] detectron2.evaluation.evaluator INFO: Inference done 658/2290. 0.0687 s / img. ETA=0:01:54
[08/06 07:48:14] detectron2.evaluation.evaluator INFO: Inference done 730/2290. 0.0687 s / img. ETA=0:01:49
[08/06 07:48:19] detectron2.evaluation.evaluator INFO: Inference done 802/2290. 0.0687 s / img. ETA=0:01:44
[08/06 07:48:24] detectron2.evaluation.evaluator INFO: Inference done 870/2290. 0.0690 s / img. ETA=0:01:39
[08/06 07:48:30] detectron2.evaluation.evaluator INFO: Inference done 940/2290. 0.0692 s / img. ETA=0:01:35
[08/06 07:48:35] detectron2.evaluation.evaluator INFO: Inference done 1011/2290. 0.0692 s / img. ETA=0:01:30
[08/06 07:48:40] detectron2.evaluation.evaluator INFO: Inference done 1085/2290. 0.0690 s / img. ETA=0:01:24
[08/06 07:48:45] detectron2.evaluation.evaluator INFO: Inference done 1156/2290. 0.0691 s / img. ETA=0:01:19
[08/06 07:48:50] detectron2.evaluation.evaluator INFO: Inference done 1227/2290. 0.0691 s / img. ETA=0:01:14
[08/06 07:48:55] detectron2.evaluation.evaluator INFO: Inference done 1300/2290. 0.0690 s / img. ETA=0:01:09
[08/06 07:49:00] detectron2.evaluation.evaluator INFO: Inference done 1369/2290. 0.0692 s / img. ETA=0:01:04
[08/06 07:49:05] detectron2.evaluation.evaluator INFO: Inference done 1438/2290. 0.0693 s / img. ETA=0:01:00
[08/06 07:49:10] detectron2.evaluation.evaluator INFO: Inference done 1510/2290. 0.0693 s / img. ETA=0:00:55
[08/06 07:49:15] detectron2.evaluation.evaluator INFO: Inference done 1581/2290. 0.0693 s / img. ETA=0:00:50
[08/06 07:49:20] detectron2.evaluation.evaluator INFO: Inference done 1651/2290. 0.0694 s / img. ETA=0:00:45
[08/06 07:49:25] detectron2.evaluation.evaluator INFO: Inference done 1722/2290. 0.0694 s / img. ETA=0:00:40
[08/06 07:49:30] detectron2.evaluation.evaluator INFO: Inference done 1793/2290. 0.0694 s / img. ETA=0:00:35
[08/06 07:49:35] detectron2.evaluation.evaluator INFO: Inference done 1864/2290. 0.0694 s / img. ETA=0:00:30
[08/06 07:49:40] detectron2.evaluation.evaluator INFO: Inference done 1936/2290. 0.0694 s / img. ETA=0:00:25
[08/06 07:49:45] detectron2.evaluation.evaluator INFO: Inference done 2008/2290. 0.0694 s / img. ETA=0:00:19
[08/06 07:49:50] detectron2.evaluation.evaluator INFO: Inference done 2078/2290. 0.0694 s / img. ETA=0:00:14
[08/06 07:49:55] detectron2.evaluation.evaluator INFO: Inference done 2148/2290. 0.0694 s / img. ETA=0:00:10
[08/06 07:50:00] detectron2.evaluation.evaluator INFO: Inference done 2219/2290. 0.0695 s / img. ETA=0:00:05
[08/06 07:50:05] detectron2.evaluation.evaluator INFO: Inference done 2290/2290. 0.0695 s / img. ETA=0:00:00
[08/06 07:50:06] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:41.841596 (0.070828 s / img per device, on 4 devices)
[08/06 07:50:06] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:38 (0.069460 s / img per device, on 4 devices)
[08/06 07:53:38] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:53:38] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:53:38] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:53:38] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:53:38] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 07:53:46] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0664 s / img. ETA=0:02:33
[08/06 07:53:51] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0668 s / img. ETA=0:02:29
[08/06 07:53:56] detectron2.evaluation.evaluator INFO: Inference done 159/2290. 0.0669 s / img. ETA=0:02:25
[08/06 07:54:01] detectron2.evaluation.evaluator INFO: Inference done 233/2290. 0.0670 s / img. ETA=0:02:20
[08/06 07:54:06] detectron2.evaluation.evaluator INFO: Inference done 307/2290. 0.0670 s / img. ETA=0:02:15
[08/06 07:54:11] detectron2.evaluation.evaluator INFO: Inference done 380/2290. 0.0671 s / img. ETA=0:02:10
[08/06 07:54:16] detectron2.evaluation.evaluator INFO: Inference done 450/2290. 0.0678 s / img. ETA=0:02:06
[08/06 07:54:21] detectron2.evaluation.evaluator INFO: Inference done 520/2290. 0.0682 s / img. ETA=0:02:02
[08/06 07:54:26] detectron2.evaluation.evaluator INFO: Inference done 593/2290. 0.0681 s / img. ETA=0:01:57
[08/06 07:54:31] detectron2.evaluation.evaluator INFO: Inference done 662/2290. 0.0685 s / img. ETA=0:01:53
[08/06 07:54:36] detectron2.evaluation.evaluator INFO: Inference done 733/2290. 0.0686 s / img. ETA=0:01:48
[08/06 07:54:41] detectron2.evaluation.evaluator INFO: Inference done 805/2290. 0.0686 s / img. ETA=0:01:43
[08/06 07:54:46] detectron2.evaluation.evaluator INFO: Inference done 878/2290. 0.0685 s / img. ETA=0:01:38
[08/06 07:54:51] detectron2.evaluation.evaluator INFO: Inference done 950/2290. 0.0686 s / img. ETA=0:01:33
[08/06 07:54:56] detectron2.evaluation.evaluator INFO: Inference done 1020/2290. 0.0687 s / img. ETA=0:01:28
[08/06 07:55:01] detectron2.evaluation.evaluator INFO: Inference done 1089/2290. 0.0689 s / img. ETA=0:01:24
[08/06 07:55:06] detectron2.evaluation.evaluator INFO: Inference done 1159/2290. 0.0690 s / img. ETA=0:01:19
[08/06 07:55:11] detectron2.evaluation.evaluator INFO: Inference done 1231/2290. 0.0690 s / img. ETA=0:01:14
[08/06 07:55:16] detectron2.evaluation.evaluator INFO: Inference done 1301/2290. 0.0691 s / img. ETA=0:01:09
[08/06 07:55:22] detectron2.evaluation.evaluator INFO: Inference done 1371/2290. 0.0692 s / img. ETA=0:01:04
[08/06 07:55:27] detectron2.evaluation.evaluator INFO: Inference done 1445/2290. 0.0691 s / img. ETA=0:00:59
[08/06 07:55:32] detectron2.evaluation.evaluator INFO: Inference done 1517/2290. 0.0691 s / img. ETA=0:00:54
[08/06 07:55:37] detectron2.evaluation.evaluator INFO: Inference done 1586/2290. 0.0692 s / img. ETA=0:00:49
[08/06 07:55:42] detectron2.evaluation.evaluator INFO: Inference done 1655/2290. 0.0693 s / img. ETA=0:00:44
[08/06 07:55:47] detectron2.evaluation.evaluator INFO: Inference done 1727/2290. 0.0693 s / img. ETA=0:00:39
[08/06 07:55:52] detectron2.evaluation.evaluator INFO: Inference done 1800/2290. 0.0692 s / img. ETA=0:00:34
[08/06 07:55:57] detectron2.evaluation.evaluator INFO: Inference done 1870/2290. 0.0693 s / img. ETA=0:00:29
[08/06 07:56:02] detectron2.evaluation.evaluator INFO: Inference done 1941/2290. 0.0693 s / img. ETA=0:00:24
[08/06 07:56:07] detectron2.evaluation.evaluator INFO: Inference done 2012/2290. 0.0693 s / img. ETA=0:00:19
[08/06 07:56:12] detectron2.evaluation.evaluator INFO: Inference done 2082/2290. 0.0693 s / img. ETA=0:00:14
[08/06 07:56:17] detectron2.evaluation.evaluator INFO: Inference done 2154/2290. 0.0693 s / img. ETA=0:00:09
[08/06 07:56:22] detectron2.evaluation.evaluator INFO: Inference done 2228/2290. 0.0692 s / img. ETA=0:00:04
[08/06 07:56:27] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:41.166873 (0.070533 s / img per device, on 4 devices)
[08/06 07:56:27] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:38 (0.069206 s / img per device, on 4 devices)
[08/06 07:59:59] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 08:00:00] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 08:00:00] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 08:00:00] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 08:00:00] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 08:00:07] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0672 s / img. ETA=0:02:35
[08/06 08:00:12] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0671 s / img. ETA=0:02:30
[08/06 08:00:17] detectron2.evaluation.evaluator INFO: Inference done 158/2290. 0.0672 s / img. ETA=0:02:26
[08/06 08:00:22] detectron2.evaluation.evaluator INFO: Inference done 231/2290. 0.0672 s / img. ETA=0:02:21
[08/06 08:00:28] detectron2.evaluation.evaluator INFO: Inference done 303/2290. 0.0676 s / img. ETA=0:02:17
[08/06 08:00:33] detectron2.evaluation.evaluator INFO: Inference done 374/2290. 0.0679 s / img. ETA=0:02:12
[08/06 08:00:38] detectron2.evaluation.evaluator INFO: Inference done 445/2290. 0.0682 s / img. ETA=0:02:08
[08/06 08:00:43] detectron2.evaluation.evaluator INFO: Inference done 516/2290. 0.0684 s / img. ETA=0:02:03
[08/06 08:00:48] detectron2.evaluation.evaluator INFO: Inference done 586/2290. 0.0687 s / img. ETA=0:01:59
[08/06 08:00:53] detectron2.evaluation.evaluator INFO: Inference done 657/2290. 0.0687 s / img. ETA=0:01:54
[08/06 08:00:58] detectron2.evaluation.evaluator INFO: Inference done 729/2290. 0.0687 s / img. ETA=0:01:49
[08/06 08:01:03] detectron2.evaluation.evaluator INFO: Inference done 800/2290. 0.0689 s / img. ETA=0:01:44
[08/06 08:01:08] detectron2.evaluation.evaluator INFO: Inference done 868/2290. 0.0692 s / img. ETA=0:01:40
[08/06 08:01:13] detectron2.evaluation.evaluator INFO: Inference done 937/2290. 0.0693 s / img. ETA=0:01:35
[08/06 08:01:18] detectron2.evaluation.evaluator INFO: Inference done 1008/2290. 0.0694 s / img. ETA=0:01:30
[08/06 08:01:23] detectron2.evaluation.evaluator INFO: Inference done 1080/2290. 0.0693 s / img. ETA=0:01:25
[08/06 08:01:28] detectron2.evaluation.evaluator INFO: Inference done 1151/2290. 0.0693 s / img. ETA=0:01:20
[08/06 08:01:33] detectron2.evaluation.evaluator INFO: Inference done 1223/2290. 0.0693 s / img. ETA=0:01:15
[08/06 08:01:38] detectron2.evaluation.evaluator INFO: Inference done 1293/2290. 0.0694 s / img. ETA=0:01:10
[08/06 08:01:43] detectron2.evaluation.evaluator INFO: Inference done 1361/2290. 0.0695 s / img. ETA=0:01:05
[08/06 08:01:48] detectron2.evaluation.evaluator INFO: Inference done 1430/2290. 0.0696 s / img. ETA=0:01:01
[08/06 08:01:53] detectron2.evaluation.evaluator INFO: Inference done 1501/2290. 0.0696 s / img. ETA=0:00:55
[08/06 08:01:58] detectron2.evaluation.evaluator INFO: Inference done 1571/2290. 0.0697 s / img. ETA=0:00:51
[08/06 08:02:03] detectron2.evaluation.evaluator INFO: Inference done 1642/2290. 0.0697 s / img. ETA=0:00:46
[08/06 08:02:08] detectron2.evaluation.evaluator INFO: Inference done 1712/2290. 0.0697 s / img. ETA=0:00:41
[08/06 08:02:13] detectron2.evaluation.evaluator INFO: Inference done 1782/2290. 0.0697 s / img. ETA=0:00:36
[08/06 08:02:18] detectron2.evaluation.evaluator INFO: Inference done 1851/2290. 0.0698 s / img. ETA=0:00:31
[08/06 08:02:23] detectron2.evaluation.evaluator INFO: Inference done 1922/2290. 0.0698 s / img. ETA=0:00:26
[08/06 08:02:28] detectron2.evaluation.evaluator INFO: Inference done 1992/2290. 0.0698 s / img. ETA=0:00:21
[08/06 08:02:33] detectron2.evaluation.evaluator INFO: Inference done 2063/2290. 0.0698 s / img. ETA=0:00:16
[08/06 08:02:38] detectron2.evaluation.evaluator INFO: Inference done 2132/2290. 0.0699 s / img. ETA=0:00:11
[08/06 08:02:43] detectron2.evaluation.evaluator INFO: Inference done 2203/2290. 0.0699 s / img. ETA=0:00:06
[08/06 08:02:48] detectron2.evaluation.evaluator INFO: Inference done 2273/2290. 0.0699 s / img. ETA=0:00:01
[08/06 08:02:50] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:42.987908 (0.071330 s / img per device, on 4 devices)
[08/06 08:02:50] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:39 (0.069892 s / img per device, on 4 devices)
[08/06 08:03:14] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
    return self._process_data(data)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
    data.reraise()
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
OSError: Caught OSError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
    data = fetcher.fetch(index)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/dataset_mapper.py", line 78, in __call__
    image = utils.read_image(dataset_dict["file_name"], format=self.img_format)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/detection_utils.py", line 62, in read_image
    image = image.convert(conversion_format)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/PIL/Image.py", line 915, in convert
    self.load()
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/PIL/ImageFile.py", line 249, in load
    raise OSError(
OSError: image file is truncated (8 bytes not processed)

[08/06 08:03:14] detectron2.engine.hooks INFO: Overall training speed: 5110 iterations in 0:17:54 (0.2103 s / it)
[08/06 08:03:14] detectron2.engine.hooks INFO: Total training time: 0:32:13 (0:14:19 on hooks)
[08/06 08:16:12] detectron2 INFO: Rank of current process: 3. World size: 4
[08/06 08:16:13] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 08:16:13] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 08:16:13] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 08:16:13] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 08:16:14] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 08:16:16] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 08:16:16] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 08:16:16] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 08:16:18] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 08:16:18] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 08:16:18] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 08:16:18] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 08:16:18] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 08:16:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0024999.pth ...
[08/06 08:16:19] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0024999.pth ...
[08/06 08:16:19] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0024999.pth ...
[08/06 08:16:19] detectron2.engine.train_loop INFO: Starting training from iteration 25000
[08/06 08:19:50] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 08:19:50] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 08:19:50] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 08:19:51] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 08:19:51] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 08:19:58] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0662 s / img. ETA=0:02:32
[08/06 08:20:03] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0668 s / img. ETA=0:02:30
[08/06 08:20:08] detectron2.evaluation.evaluator INFO: Inference done 159/2290. 0.0669 s / img. ETA=0:02:25
[08/06 08:20:13] detectron2.evaluation.evaluator INFO: Inference done 232/2290. 0.0670 s / img. ETA=0:02:20
[08/06 08:20:18] detectron2.evaluation.evaluator INFO: Inference done 306/2290. 0.0670 s / img. ETA=0:02:15
[08/06 08:20:23] detectron2.evaluation.evaluator INFO: Inference done 380/2290. 0.0670 s / img. ETA=0:02:10
[08/06 08:20:28] detectron2.evaluation.evaluator INFO: Inference done 452/2290. 0.0673 s / img. ETA=0:02:06
[08/06 08:20:33] detectron2.evaluation.evaluator INFO: Inference done 522/2290. 0.0678 s / img. ETA=0:02:02
[08/06 08:20:38] detectron2.evaluation.evaluator INFO: Inference done 592/2290. 0.0681 s / img. ETA=0:01:57
[08/06 08:20:43] detectron2.evaluation.evaluator INFO: Inference done 664/2290. 0.0682 s / img. ETA=0:01:52
[08/06 08:20:48] detectron2.evaluation.evaluator INFO: Inference done 733/2290. 0.0685 s / img. ETA=0:01:48
[08/06 08:20:53] detectron2.evaluation.evaluator INFO: Inference done 803/2290. 0.0687 s / img. ETA=0:01:44
[08/06 08:20:59] detectron2.evaluation.evaluator INFO: Inference done 875/2290. 0.0687 s / img. ETA=0:01:39
[08/06 08:21:04] detectron2.evaluation.evaluator INFO: Inference done 949/2290. 0.0686 s / img. ETA=0:01:33
[08/06 08:21:09] detectron2.evaluation.evaluator INFO: Inference done 1022/2290. 0.0686 s / img. ETA=0:01:28
[08/06 08:21:14] detectron2.evaluation.evaluator INFO: Inference done 1093/2290. 0.0686 s / img. ETA=0:01:23
[08/06 08:21:19] detectron2.evaluation.evaluator INFO: Inference done 1163/2290. 0.0687 s / img. ETA=0:01:18
[08/06 08:21:24] detectron2.evaluation.evaluator INFO: Inference done 1234/2290. 0.0688 s / img. ETA=0:01:13
[08/06 08:21:29] detectron2.evaluation.evaluator INFO: Inference done 1308/2290. 0.0687 s / img. ETA=0:01:08
[08/06 08:21:34] detectron2.evaluation.evaluator INFO: Inference done 1382/2290. 0.0686 s / img. ETA=0:01:03
[08/06 08:21:39] detectron2.evaluation.evaluator INFO: Inference done 1452/2290. 0.0687 s / img. ETA=0:00:58
[08/06 08:21:44] detectron2.evaluation.evaluator INFO: Inference done 1521/2290. 0.0688 s / img. ETA=0:00:53
[08/06 08:21:49] detectron2.evaluation.evaluator INFO: Inference done 1590/2290. 0.0689 s / img. ETA=0:00:49
[08/06 08:21:54] detectron2.evaluation.evaluator INFO: Inference done 1661/2290. 0.0690 s / img. ETA=0:00:44
[08/06 08:21:59] detectron2.evaluation.evaluator INFO: Inference done 1733/2290. 0.0689 s / img. ETA=0:00:39
[08/06 08:22:04] detectron2.evaluation.evaluator INFO: Inference done 1804/2290. 0.0690 s / img. ETA=0:00:34
[08/06 08:22:09] detectron2.evaluation.evaluator INFO: Inference done 1876/2290. 0.0690 s / img. ETA=0:00:29
[08/06 08:22:14] detectron2.evaluation.evaluator INFO: Inference done 1950/2290. 0.0689 s / img. ETA=0:00:23
[08/06 08:22:19] detectron2.evaluation.evaluator INFO: Inference done 2024/2290. 0.0688 s / img. ETA=0:00:18
[08/06 08:22:24] detectron2.evaluation.evaluator INFO: Inference done 2096/2290. 0.0688 s / img. ETA=0:00:13
[08/06 08:22:29] detectron2.evaluation.evaluator INFO: Inference done 2169/2290. 0.0688 s / img. ETA=0:00:08
[08/06 08:22:34] detectron2.evaluation.evaluator INFO: Inference done 2238/2290. 0.0689 s / img. ETA=0:00:03
[08/06 08:22:38] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:40.701798 (0.070329 s / img per device, on 4 devices)
[08/06 08:22:38] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:37 (0.068936 s / img per device, on 4 devices)
[08/06 08:22:43] detectron2.engine.hooks INFO: Overall training speed: 1014 iterations in 0:03:26 (0.2033 s / it)
[08/06 08:22:43] detectron2.engine.hooks INFO: Total training time: 0:06:16 (0:02:49 on hooks)
[08/06 08:29:02] detectron2 INFO: Rank of current process: 3. World size: 4
[08/06 08:29:03] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 08:29:03] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 08:29:03] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 08:29:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 08:29:04] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 08:29:06] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 08:29:06] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 08:29:06] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 08:29:08] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 08:29:08] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 08:29:08] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 08:29:08] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 08:29:08] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 08:29:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0025999.pth ...
[08/06 08:29:08] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0025999.pth ...
[08/06 08:29:08] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0025999.pth ...
[08/06 08:29:08] detectron2.engine.train_loop INFO: Starting training from iteration 26000
[08/06 08:39:56] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 08:39:56] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 08:39:57] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 08:39:57] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 08:39:57] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 08:40:04] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0667 s / img. ETA=0:02:33
[08/06 08:40:09] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0667 s / img. ETA=0:02:29
[08/06 08:40:14] detectron2.evaluation.evaluator INFO: Inference done 159/2290. 0.0667 s / img. ETA=0:02:24
[08/06 08:40:19] detectron2.evaluation.evaluator INFO: Inference done 233/2290. 0.0669 s / img. ETA=0:02:20
[08/06 08:40:24] detectron2.evaluation.evaluator INFO: Inference done 305/2290. 0.0672 s / img. ETA=0:02:15
[08/06 08:40:29] detectron2.evaluation.evaluator INFO: Inference done 379/2290. 0.0672 s / img. ETA=0:02:10
[08/06 08:40:35] detectron2.evaluation.evaluator INFO: Inference done 453/2290. 0.0672 s / img. ETA=0:02:05
[08/06 08:40:40] detectron2.evaluation.evaluator INFO: Inference done 527/2290. 0.0672 s / img. ETA=0:02:00
[08/06 08:40:45] detectron2.evaluation.evaluator INFO: Inference done 601/2290. 0.0671 s / img. ETA=0:01:55
[08/06 08:40:50] detectron2.evaluation.evaluator INFO: Inference done 673/2290. 0.0673 s / img. ETA=0:01:50
[08/06 08:40:55] detectron2.evaluation.evaluator INFO: Inference done 746/2290. 0.0673 s / img. ETA=0:01:45
[08/06 08:41:00] detectron2.evaluation.evaluator INFO: Inference done 820/2290. 0.0673 s / img. ETA=0:01:40
[08/06 08:41:05] detectron2.evaluation.evaluator INFO: Inference done 894/2290. 0.0673 s / img. ETA=0:01:35
[08/06 08:41:10] detectron2.evaluation.evaluator INFO: Inference done 967/2290. 0.0673 s / img. ETA=0:01:30
[08/06 08:41:15] detectron2.evaluation.evaluator INFO: Inference done 1039/2290. 0.0674 s / img. ETA=0:01:25
[08/06 08:41:20] detectron2.evaluation.evaluator INFO: Inference done 1109/2290. 0.0677 s / img. ETA=0:01:21
[08/06 08:41:25] detectron2.evaluation.evaluator INFO: Inference done 1181/2290. 0.0677 s / img. ETA=0:01:16
[08/06 08:41:30] detectron2.evaluation.evaluator INFO: Inference done 1255/2290. 0.0677 s / img. ETA=0:01:11
[08/06 08:41:35] detectron2.evaluation.evaluator INFO: Inference done 1329/2290. 0.0676 s / img. ETA=0:01:06
[08/06 08:41:40] detectron2.evaluation.evaluator INFO: Inference done 1403/2290. 0.0676 s / img. ETA=0:01:01
[08/06 08:41:45] detectron2.evaluation.evaluator INFO: Inference done 1476/2290. 0.0676 s / img. ETA=0:00:56
[08/06 08:41:50] detectron2.evaluation.evaluator INFO: Inference done 1550/2290. 0.0675 s / img. ETA=0:00:50
[08/06 08:41:55] detectron2.evaluation.evaluator INFO: Inference done 1624/2290. 0.0675 s / img. ETA=0:00:45
[08/06 08:42:00] detectron2.evaluation.evaluator INFO: Inference done 1698/2290. 0.0675 s / img. ETA=0:00:40
[08/06 08:42:05] detectron2.evaluation.evaluator INFO: Inference done 1772/2290. 0.0675 s / img. ETA=0:00:35
[08/06 08:42:10] detectron2.evaluation.evaluator INFO: Inference done 1846/2290. 0.0675 s / img. ETA=0:00:30
[08/06 08:42:15] detectron2.evaluation.evaluator INFO: Inference done 1919/2290. 0.0675 s / img. ETA=0:00:25
[08/06 08:42:20] detectron2.evaluation.evaluator INFO: Inference done 1990/2290. 0.0675 s / img. ETA=0:00:20
[08/06 08:42:25] detectron2.evaluation.evaluator INFO: Inference done 2061/2290. 0.0676 s / img. ETA=0:00:15
[08/06 08:42:30] detectron2.evaluation.evaluator INFO: Inference done 2133/2290. 0.0676 s / img. ETA=0:00:10
[08/06 08:42:35] detectron2.evaluation.evaluator INFO: Inference done 2205/2290. 0.0677 s / img. ETA=0:00:05
[08/06 08:42:41] detectron2.evaluation.evaluator INFO: Inference done 2278/2290. 0.0677 s / img. ETA=0:00:00
[08/06 08:42:42] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:37.730656 (0.069029 s / img per device, on 4 devices)
[08/06 08:42:42] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:34 (0.067663 s / img per device, on 4 devices)
[08/06 08:45:41] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 363, in __next__
    data = self._next_data()
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 989, in _next_data
    return self._process_data(data)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1014, in _process_data
    data.reraise()
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
OSError: Caught OSError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 185, in _worker_loop
    data = fetcher.fetch(index)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/dataset_mapper.py", line 78, in __call__
    image = utils.read_image(dataset_dict["file_name"], format=self.img_format)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/data/detection_utils.py", line 62, in read_image
    image = image.convert(conversion_format)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/PIL/Image.py", line 915, in convert
    self.load()
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/PIL/ImageFile.py", line 249, in load
    raise OSError(
OSError: image file is truncated (8 bytes not processed)

[08/06 08:45:41] detectron2.engine.hooks INFO: Overall training speed: 1276 iterations in 0:13:35 (0.6391 s / it)
[08/06 08:45:41] detectron2.engine.hooks INFO: Total training time: 0:16:24 (0:02:48 on hooks)
[08/06 08:57:55] detectron2 INFO: Rank of current process: 3. World size: 4
[08/06 08:57:56] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 08:57:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 08:57:56] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 08:57:56] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 08:57:57] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 08:57:59] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 08:58:00] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 08:58:00] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 08:58:01] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 08:58:01] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 08:58:01] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 08:58:01] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 08:58:01] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 08:58:01] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0026999.pth ...
[08/06 08:58:02] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0026999.pth ...
[08/06 08:58:02] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0026999.pth ...
[08/06 08:58:02] detectron2.engine.train_loop INFO: Starting training from iteration 27000
[08/06 09:08:49] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 09:08:50] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 09:08:50] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 09:08:50] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 09:08:50] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 09:08:58] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0664 s / img. ETA=0:02:33
[08/06 09:09:03] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0667 s / img. ETA=0:02:29
[08/06 09:09:08] detectron2.evaluation.evaluator INFO: Inference done 159/2290. 0.0668 s / img. ETA=0:02:24
[08/06 09:09:13] detectron2.evaluation.evaluator INFO: Inference done 232/2290. 0.0670 s / img. ETA=0:02:20
[08/06 09:09:18] detectron2.evaluation.evaluator INFO: Inference done 304/2290. 0.0674 s / img. ETA=0:02:16
[08/06 09:09:23] detectron2.evaluation.evaluator INFO: Inference done 378/2290. 0.0673 s / img. ETA=0:02:11
[08/06 09:09:28] detectron2.evaluation.evaluator INFO: Inference done 452/2290. 0.0672 s / img. ETA=0:02:05
[08/06 09:09:33] detectron2.evaluation.evaluator INFO: Inference done 525/2290. 0.0673 s / img. ETA=0:02:01
[08/06 09:09:38] detectron2.evaluation.evaluator INFO: Inference done 595/2290. 0.0677 s / img. ETA=0:01:56
[08/06 09:09:43] detectron2.evaluation.evaluator INFO: Inference done 664/2290. 0.0681 s / img. ETA=0:01:52
[08/06 09:09:48] detectron2.evaluation.evaluator INFO: Inference done 736/2290. 0.0681 s / img. ETA=0:01:47
[08/06 09:09:53] detectron2.evaluation.evaluator INFO: Inference done 808/2290. 0.0682 s / img. ETA=0:01:42
[08/06 09:09:58] detectron2.evaluation.evaluator INFO: Inference done 882/2290. 0.0681 s / img. ETA=0:01:37
[08/06 09:10:03] detectron2.evaluation.evaluator INFO: Inference done 956/2290. 0.0680 s / img. ETA=0:01:32
[08/06 09:10:08] detectron2.evaluation.evaluator INFO: Inference done 1028/2290. 0.0680 s / img. ETA=0:01:27
[08/06 09:10:13] detectron2.evaluation.evaluator INFO: Inference done 1100/2290. 0.0681 s / img. ETA=0:01:22
[08/06 09:10:18] detectron2.evaluation.evaluator INFO: Inference done 1169/2290. 0.0683 s / img. ETA=0:01:18
[08/06 09:10:23] detectron2.evaluation.evaluator INFO: Inference done 1241/2290. 0.0684 s / img. ETA=0:01:13
[08/06 09:10:28] detectron2.evaluation.evaluator INFO: Inference done 1313/2290. 0.0684 s / img. ETA=0:01:08
[08/06 09:10:33] detectron2.evaluation.evaluator INFO: Inference done 1384/2290. 0.0684 s / img. ETA=0:01:03
[08/06 09:10:38] detectron2.evaluation.evaluator INFO: Inference done 1457/2290. 0.0684 s / img. ETA=0:00:58
[08/06 09:10:44] detectron2.evaluation.evaluator INFO: Inference done 1529/2290. 0.0684 s / img. ETA=0:00:53
[08/06 09:10:49] detectron2.evaluation.evaluator INFO: Inference done 1599/2290. 0.0685 s / img. ETA=0:00:48
[08/06 09:10:54] detectron2.evaluation.evaluator INFO: Inference done 1672/2290. 0.0685 s / img. ETA=0:00:43
[08/06 09:10:59] detectron2.evaluation.evaluator INFO: Inference done 1745/2290. 0.0684 s / img. ETA=0:00:37
[08/06 09:11:04] detectron2.evaluation.evaluator INFO: Inference done 1815/2290. 0.0685 s / img. ETA=0:00:33
[08/06 09:11:09] detectron2.evaluation.evaluator INFO: Inference done 1887/2290. 0.0685 s / img. ETA=0:00:28
[08/06 09:11:14] detectron2.evaluation.evaluator INFO: Inference done 1959/2290. 0.0685 s / img. ETA=0:00:23
[08/06 09:11:19] detectron2.evaluation.evaluator INFO: Inference done 2032/2290. 0.0685 s / img. ETA=0:00:17
[08/06 09:11:24] detectron2.evaluation.evaluator INFO: Inference done 2105/2290. 0.0684 s / img. ETA=0:00:12
[08/06 09:11:29] detectron2.evaluation.evaluator INFO: Inference done 2176/2290. 0.0685 s / img. ETA=0:00:07
[08/06 09:11:34] detectron2.evaluation.evaluator INFO: Inference done 2247/2290. 0.0685 s / img. ETA=0:00:03
[08/06 09:11:37] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:39.790226 (0.069930 s / img per device, on 4 devices)
[08/06 09:11:37] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:36 (0.068541 s / img per device, on 4 devices)
[08/06 09:13:02] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 09:13:02] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 09:13:03] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 09:13:03] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 09:13:03] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 09:13:10] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0668 s / img. ETA=0:02:33
[08/06 09:13:15] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0666 s / img. ETA=0:02:29
[08/06 09:13:20] detectron2.evaluation.evaluator INFO: Inference done 159/2290. 0.0667 s / img. ETA=0:02:24
[08/06 09:13:25] detectron2.evaluation.evaluator INFO: Inference done 233/2290. 0.0667 s / img. ETA=0:02:19
[08/06 09:13:30] detectron2.evaluation.evaluator INFO: Inference done 307/2290. 0.0668 s / img. ETA=0:02:14
[08/06 09:13:35] detectron2.evaluation.evaluator INFO: Inference done 381/2290. 0.0668 s / img. ETA=0:02:09
[08/06 09:13:40] detectron2.evaluation.evaluator INFO: Inference done 455/2290. 0.0669 s / img. ETA=0:02:04
[08/06 09:13:45] detectron2.evaluation.evaluator INFO: Inference done 526/2290. 0.0673 s / img. ETA=0:02:00
[08/06 09:13:51] detectron2.evaluation.evaluator INFO: Inference done 597/2290. 0.0676 s / img. ETA=0:01:56
[08/06 09:13:56] detectron2.evaluation.evaluator INFO: Inference done 670/2290. 0.0677 s / img. ETA=0:01:51
[08/06 09:14:01] detectron2.evaluation.evaluator INFO: Inference done 739/2290. 0.0680 s / img. ETA=0:01:47
[08/06 09:14:06] detectron2.evaluation.evaluator INFO: Inference done 810/2290. 0.0682 s / img. ETA=0:01:42
[08/06 09:14:11] detectron2.evaluation.evaluator INFO: Inference done 880/2290. 0.0684 s / img. ETA=0:01:38
[08/06 09:14:16] detectron2.evaluation.evaluator INFO: Inference done 950/2290. 0.0685 s / img. ETA=0:01:33
[08/06 09:14:21] detectron2.evaluation.evaluator INFO: Inference done 1021/2290. 0.0686 s / img. ETA=0:01:28
[08/06 09:14:26] detectron2.evaluation.evaluator INFO: Inference done 1094/2290. 0.0685 s / img. ETA=0:01:23
[08/06 09:14:31] detectron2.evaluation.evaluator INFO: Inference done 1166/2290. 0.0685 s / img. ETA=0:01:18
[08/06 09:14:36] detectron2.evaluation.evaluator INFO: Inference done 1236/2290. 0.0686 s / img. ETA=0:01:13
[08/06 09:14:41] detectron2.evaluation.evaluator INFO: Inference done 1308/2290. 0.0686 s / img. ETA=0:01:08
[08/06 09:14:46] detectron2.evaluation.evaluator INFO: Inference done 1377/2290. 0.0687 s / img. ETA=0:01:03
[08/06 09:14:51] detectron2.evaluation.evaluator INFO: Inference done 1448/2290. 0.0687 s / img. ETA=0:00:58
[08/06 09:14:56] detectron2.evaluation.evaluator INFO: Inference done 1518/2290. 0.0688 s / img. ETA=0:00:54
[08/06 09:15:01] detectron2.evaluation.evaluator INFO: Inference done 1590/2290. 0.0688 s / img. ETA=0:00:49
[08/06 09:15:06] detectron2.evaluation.evaluator INFO: Inference done 1664/2290. 0.0687 s / img. ETA=0:00:43
[08/06 09:15:11] detectron2.evaluation.evaluator INFO: Inference done 1738/2290. 0.0687 s / img. ETA=0:00:38
[08/06 09:15:16] detectron2.evaluation.evaluator INFO: Inference done 1809/2290. 0.0687 s / img. ETA=0:00:33
[08/06 09:15:21] detectron2.evaluation.evaluator INFO: Inference done 1879/2290. 0.0688 s / img. ETA=0:00:28
[08/06 09:15:26] detectron2.evaluation.evaluator INFO: Inference done 1949/2290. 0.0689 s / img. ETA=0:00:23
[08/06 09:15:31] detectron2.evaluation.evaluator INFO: Inference done 2020/2290. 0.0689 s / img. ETA=0:00:18
[08/06 09:15:36] detectron2.evaluation.evaluator INFO: Inference done 2094/2290. 0.0688 s / img. ETA=0:00:13
[08/06 09:15:41] detectron2.evaluation.evaluator INFO: Inference done 2168/2290. 0.0688 s / img. ETA=0:00:08
[08/06 09:15:46] detectron2.evaluation.evaluator INFO: Inference done 2242/2290. 0.0687 s / img. ETA=0:00:03
[08/06 09:15:50] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:40.092437 (0.070062 s / img per device, on 4 devices)
[08/06 09:15:50] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:36 (0.068704 s / img per device, on 4 devices)
[08/06 09:15:52] detectron2.engine.hooks INFO: Overall training speed: 1122 iterations in 0:11:58 (0.6403 s / it)
[08/06 09:15:52] detectron2.engine.hooks INFO: Total training time: 0:17:41 (0:05:43 on hooks)
[08/06 09:26:13] detectron2 INFO: Rank of current process: 3. World size: 4
[08/06 09:26:13] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 09:26:13] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 09:26:13] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 09:26:13] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 09:26:14] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 09:26:16] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 09:26:17] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 09:26:17] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 09:26:18] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 09:26:18] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 09:26:18] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 09:26:18] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 09:26:18] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 09:26:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_final.pth ...
[08/06 09:26:19] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_final.pth ...
[08/06 09:26:19] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_final.pth ...
[08/06 09:26:19] detectron2.engine.train_loop INFO: Starting training from iteration 28125
[08/06 09:26:19] detectron2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/06 09:28:16] detectron2 INFO: Rank of current process: 3. World size: 4
[08/06 09:28:17] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 09:28:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', './Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth'], resume=False)
[08/06 09:28:17] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 09:28:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 09:28:17] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 09:28:19] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 09:28:20] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 09:28:20] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 09:28:21] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 09:28:21] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 09:28:22] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 09:28:22] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 09:28:22] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 09:28:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth ...
[08/06 09:28:22] detectron2.engine.train_loop INFO: Starting training from iteration 28000
[08/06 09:29:48] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 09:29:48] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 09:29:49] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 09:29:49] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 09:29:49] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 09:29:56] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0660 s / img. ETA=0:02:32
[08/06 09:30:01] detectron2.evaluation.evaluator INFO: Inference done 86/2290. 0.0663 s / img. ETA=0:02:28
[08/06 09:30:06] detectron2.evaluation.evaluator INFO: Inference done 160/2290. 0.0663 s / img. ETA=0:02:23
[08/06 09:30:11] detectron2.evaluation.evaluator INFO: Inference done 234/2290. 0.0664 s / img. ETA=0:02:19
[08/06 09:30:16] detectron2.evaluation.evaluator INFO: Inference done 308/2290. 0.0664 s / img. ETA=0:02:14
[08/06 09:30:21] detectron2.evaluation.evaluator INFO: Inference done 382/2290. 0.0665 s / img. ETA=0:02:09
[08/06 09:30:26] detectron2.evaluation.evaluator INFO: Inference done 456/2290. 0.0665 s / img. ETA=0:02:04
[08/06 09:30:31] detectron2.evaluation.evaluator INFO: Inference done 530/2290. 0.0665 s / img. ETA=0:01:59
[08/06 09:30:36] detectron2.evaluation.evaluator INFO: Inference done 604/2290. 0.0666 s / img. ETA=0:01:54
[08/06 09:30:41] detectron2.evaluation.evaluator INFO: Inference done 677/2290. 0.0667 s / img. ETA=0:01:49
[08/06 09:30:46] detectron2.evaluation.evaluator INFO: Inference done 751/2290. 0.0667 s / img. ETA=0:01:44
[08/06 09:30:52] detectron2.evaluation.evaluator INFO: Inference done 825/2290. 0.0667 s / img. ETA=0:01:39
[08/06 09:30:57] detectron2.evaluation.evaluator INFO: Inference done 899/2290. 0.0668 s / img. ETA=0:01:34
[08/06 09:31:02] detectron2.evaluation.evaluator INFO: Inference done 972/2290. 0.0669 s / img. ETA=0:01:29
[08/06 09:31:07] detectron2.evaluation.evaluator INFO: Inference done 1043/2290. 0.0670 s / img. ETA=0:01:25
[08/06 09:31:12] detectron2.evaluation.evaluator INFO: Inference done 1112/2290. 0.0673 s / img. ETA=0:01:20
[08/06 09:31:17] detectron2.evaluation.evaluator INFO: Inference done 1182/2290. 0.0675 s / img. ETA=0:01:16
[08/06 09:31:22] detectron2.evaluation.evaluator INFO: Inference done 1255/2290. 0.0675 s / img. ETA=0:01:11
[08/06 09:31:27] detectron2.evaluation.evaluator INFO: Inference done 1326/2290. 0.0677 s / img. ETA=0:01:06
[08/06 09:31:32] detectron2.evaluation.evaluator INFO: Inference done 1399/2290. 0.0676 s / img. ETA=0:01:01
[08/06 09:31:37] detectron2.evaluation.evaluator INFO: Inference done 1469/2290. 0.0678 s / img. ETA=0:00:56
[08/06 09:31:42] detectron2.evaluation.evaluator INFO: Inference done 1539/2290. 0.0679 s / img. ETA=0:00:51
[08/06 09:31:47] detectron2.evaluation.evaluator INFO: Inference done 1609/2290. 0.0680 s / img. ETA=0:00:47
[08/06 09:31:52] detectron2.evaluation.evaluator INFO: Inference done 1680/2290. 0.0681 s / img. ETA=0:00:42
[08/06 09:31:57] detectron2.evaluation.evaluator INFO: Inference done 1754/2290. 0.0680 s / img. ETA=0:00:37
[08/06 09:32:02] detectron2.evaluation.evaluator INFO: Inference done 1828/2290. 0.0680 s / img. ETA=0:00:32
[08/06 09:32:07] detectron2.evaluation.evaluator INFO: Inference done 1901/2290. 0.0680 s / img. ETA=0:00:26
[08/06 09:32:12] detectron2.evaluation.evaluator INFO: Inference done 1972/2290. 0.0681 s / img. ETA=0:00:22
[08/06 09:32:17] detectron2.evaluation.evaluator INFO: Inference done 2041/2290. 0.0682 s / img. ETA=0:00:17
[08/06 09:32:22] detectron2.evaluation.evaluator INFO: Inference done 2111/2290. 0.0683 s / img. ETA=0:00:12
[08/06 09:32:27] detectron2.evaluation.evaluator INFO: Inference done 2183/2290. 0.0683 s / img. ETA=0:00:07
[08/06 09:32:32] detectron2.evaluation.evaluator INFO: Inference done 2257/2290. 0.0683 s / img. ETA=0:00:02
[08/06 09:32:35] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:39.057019 (0.069609 s / img per device, on 4 devices)
[08/06 09:32:35] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:35 (0.068237 s / img per device, on 4 devices)
[08/06 09:32:38] detectron2.engine.hooks INFO: Overall training speed: 122 iterations in 0:01:16 (0.6289 s / it)
[08/06 09:32:38] detectron2.engine.hooks INFO: Total training time: 0:04:06 (0:02:50 on hooks)
[08/06 20:56:35] detectron2 INFO: Rank of current process: 3. World size: 4
[08/06 20:56:35] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 20:56:35] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', './Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth'], resume=False)
[08/06 20:56:35] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 20:56:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 20:56:36] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 20:56:38] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 20:56:39] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 20:56:39] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 20:56:40] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 20:56:40] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 20:56:40] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 20:56:40] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 20:56:40] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 20:56:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth ...
[08/06 20:56:41] detectron2.engine.train_loop INFO: Starting training from iteration 28000
[08/06 20:58:05] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 20:58:05] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 20:58:06] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 20:58:06] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 20:58:06] detectron2.evaluation.evaluator INFO: Start inference on 2290 images
[08/06 20:58:13] detectron2.evaluation.evaluator INFO: Inference done 11/2290. 0.0664 s / img. ETA=0:02:33
[08/06 20:58:18] detectron2.evaluation.evaluator INFO: Inference done 85/2290. 0.0664 s / img. ETA=0:02:29
[08/06 20:58:23] detectron2.evaluation.evaluator INFO: Inference done 159/2290. 0.0665 s / img. ETA=0:02:24
[08/06 20:58:29] detectron2.evaluation.evaluator INFO: Inference done 233/2290. 0.0666 s / img. ETA=0:02:19
[08/06 20:58:34] detectron2.evaluation.evaluator INFO: Inference done 307/2290. 0.0666 s / img. ETA=0:02:14
[08/06 20:58:39] detectron2.evaluation.evaluator INFO: Inference done 381/2290. 0.0667 s / img. ETA=0:02:09
[08/06 20:58:44] detectron2.evaluation.evaluator INFO: Inference done 455/2290. 0.0667 s / img. ETA=0:02:04
[08/06 20:58:49] detectron2.evaluation.evaluator INFO: Inference done 529/2290. 0.0668 s / img. ETA=0:01:59
[08/06 20:58:54] detectron2.evaluation.evaluator INFO: Inference done 602/2290. 0.0669 s / img. ETA=0:01:55
[08/06 20:58:59] detectron2.evaluation.evaluator INFO: Inference done 675/2290. 0.0669 s / img. ETA=0:01:50
[08/06 20:59:04] detectron2.evaluation.evaluator INFO: Inference done 745/2290. 0.0673 s / img. ETA=0:01:45
[08/06 20:59:09] detectron2.evaluation.evaluator INFO: Inference done 818/2290. 0.0673 s / img. ETA=0:01:41
[08/06 20:59:14] detectron2.evaluation.evaluator INFO: Inference done 891/2290. 0.0674 s / img. ETA=0:01:36
[08/06 20:59:19] detectron2.evaluation.evaluator INFO: Inference done 963/2290. 0.0675 s / img. ETA=0:01:31
[08/06 20:59:24] detectron2.evaluation.evaluator INFO: Inference done 1034/2290. 0.0676 s / img. ETA=0:01:26
[08/06 20:59:29] detectron2.evaluation.evaluator INFO: Inference done 1103/2290. 0.0679 s / img. ETA=0:01:22
[08/06 20:59:34] detectron2.evaluation.evaluator INFO: Inference done 1174/2290. 0.0680 s / img. ETA=0:01:17
[08/06 20:59:39] detectron2.evaluation.evaluator INFO: Inference done 1247/2290. 0.0680 s / img. ETA=0:01:12
[08/06 20:59:44] detectron2.evaluation.evaluator INFO: Inference done 1318/2290. 0.0681 s / img. ETA=0:01:07
[08/06 20:59:49] detectron2.evaluation.evaluator INFO: Inference done 1388/2290. 0.0683 s / img. ETA=0:01:02
[08/06 20:59:54] detectron2.evaluation.evaluator INFO: Inference done 1456/2290. 0.0685 s / img. ETA=0:00:58
[08/06 20:59:59] detectron2.evaluation.evaluator INFO: Inference done 1525/2290. 0.0686 s / img. ETA=0:00:53
[08/06 21:00:04] detectron2.evaluation.evaluator INFO: Inference done 1596/2290. 0.0687 s / img. ETA=0:00:48
[08/06 21:00:09] detectron2.evaluation.evaluator INFO: Inference done 1666/2290. 0.0687 s / img. ETA=0:00:43
[08/06 21:00:14] detectron2.evaluation.evaluator INFO: Inference done 1735/2290. 0.0689 s / img. ETA=0:00:38
[08/06 21:00:19] detectron2.evaluation.evaluator INFO: Inference done 1805/2290. 0.0689 s / img. ETA=0:00:34
[08/06 21:00:24] detectron2.evaluation.evaluator INFO: Inference done 1878/2290. 0.0689 s / img. ETA=0:00:28
[08/06 21:00:30] detectron2.evaluation.evaluator INFO: Inference done 1949/2290. 0.0689 s / img. ETA=0:00:23
[08/06 21:00:35] detectron2.evaluation.evaluator INFO: Inference done 2019/2290. 0.0690 s / img. ETA=0:00:19
[08/06 21:00:40] detectron2.evaluation.evaluator INFO: Inference done 2087/2290. 0.0691 s / img. ETA=0:00:14
[08/06 21:00:45] detectron2.evaluation.evaluator INFO: Inference done 2156/2290. 0.0691 s / img. ETA=0:00:09
[08/06 21:00:50] detectron2.evaluation.evaluator INFO: Inference done 2224/2290. 0.0692 s / img. ETA=0:00:04
[08/06 21:00:55] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:41.601261 (0.070723 s / img per device, on 4 devices)
[08/06 21:00:55] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:38 (0.069329 s / img per device, on 4 devices)
[08/06 21:00:55] detectron2.engine.hooks INFO: Overall training speed: 122 iterations in 0:01:15 (0.6167 s / it)
[08/06 21:00:55] detectron2.engine.hooks INFO: Total training time: 0:04:06 (0:02:50 on hooks)
