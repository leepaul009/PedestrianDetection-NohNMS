[08/06 07:30:46] detectron2 INFO: Rank of current process: 1. World size: 4
[08/06 07:30:47] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 07:30:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 07:30:47] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 07:30:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 07:30:48] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 07:30:50] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 07:30:50] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 07:30:50] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 07:30:51] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 07:30:51] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 07:30:52] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 07:30:52] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 07:30:52] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 07:30:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from datasets/noh_nms_model_final.pth ...
[08/06 07:30:53] detectron2.engine.train_loop INFO: Starting training from iteration 20000
[08/06 07:34:29] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:34:29] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:34:29] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:34:29] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:34:29] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 07:34:37] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0660 s / img. ETA=0:02:32
[08/06 07:34:42] detectron2.evaluation.evaluator INFO: Inference done 86/2292. 0.0662 s / img. ETA=0:02:28
[08/06 07:34:47] detectron2.evaluation.evaluator INFO: Inference done 161/2292. 0.0662 s / img. ETA=0:02:23
[08/06 07:34:52] detectron2.evaluation.evaluator INFO: Inference done 235/2292. 0.0664 s / img. ETA=0:02:19
[08/06 07:34:57] detectron2.evaluation.evaluator INFO: Inference done 309/2292. 0.0665 s / img. ETA=0:02:14
[08/06 07:35:02] detectron2.evaluation.evaluator INFO: Inference done 383/2292. 0.0666 s / img. ETA=0:02:09
[08/06 07:35:07] detectron2.evaluation.evaluator INFO: Inference done 457/2292. 0.0666 s / img. ETA=0:02:04
[08/06 07:35:12] detectron2.evaluation.evaluator INFO: Inference done 531/2292. 0.0667 s / img. ETA=0:01:59
[08/06 07:35:17] detectron2.evaluation.evaluator INFO: Inference done 605/2292. 0.0667 s / img. ETA=0:01:54
[08/06 07:35:22] detectron2.evaluation.evaluator INFO: Inference done 679/2292. 0.0667 s / img. ETA=0:01:49
[08/06 07:35:27] detectron2.evaluation.evaluator INFO: Inference done 751/2292. 0.0669 s / img. ETA=0:01:45
[08/06 07:35:32] detectron2.evaluation.evaluator INFO: Inference done 821/2292. 0.0672 s / img. ETA=0:01:40
[08/06 07:35:37] detectron2.evaluation.evaluator INFO: Inference done 895/2292. 0.0672 s / img. ETA=0:01:35
[08/06 07:35:42] detectron2.evaluation.evaluator INFO: Inference done 967/2292. 0.0673 s / img. ETA=0:01:30
[08/06 07:35:47] detectron2.evaluation.evaluator INFO: Inference done 1040/2292. 0.0673 s / img. ETA=0:01:25
[08/06 07:35:53] detectron2.evaluation.evaluator INFO: Inference done 1114/2292. 0.0673 s / img. ETA=0:01:20
[08/06 07:35:58] detectron2.evaluation.evaluator INFO: Inference done 1188/2292. 0.0673 s / img. ETA=0:01:15
[08/06 07:36:03] detectron2.evaluation.evaluator INFO: Inference done 1261/2292. 0.0673 s / img. ETA=0:01:10
[08/06 07:36:08] detectron2.evaluation.evaluator INFO: Inference done 1335/2292. 0.0673 s / img. ETA=0:01:05
[08/06 07:36:13] detectron2.evaluation.evaluator INFO: Inference done 1409/2292. 0.0673 s / img. ETA=0:01:00
[08/06 07:36:18] detectron2.evaluation.evaluator INFO: Inference done 1483/2292. 0.0673 s / img. ETA=0:00:55
[08/06 07:36:23] detectron2.evaluation.evaluator INFO: Inference done 1557/2292. 0.0673 s / img. ETA=0:00:50
[08/06 07:36:28] detectron2.evaluation.evaluator INFO: Inference done 1631/2292. 0.0672 s / img. ETA=0:00:45
[08/06 07:36:33] detectron2.evaluation.evaluator INFO: Inference done 1704/2292. 0.0673 s / img. ETA=0:00:40
[08/06 07:36:38] detectron2.evaluation.evaluator INFO: Inference done 1778/2292. 0.0673 s / img. ETA=0:00:35
[08/06 07:36:43] detectron2.evaluation.evaluator INFO: Inference done 1852/2292. 0.0672 s / img. ETA=0:00:30
[08/06 07:36:48] detectron2.evaluation.evaluator INFO: Inference done 1926/2292. 0.0672 s / img. ETA=0:00:25
[08/06 07:36:53] detectron2.evaluation.evaluator INFO: Inference done 2000/2292. 0.0672 s / img. ETA=0:00:20
[08/06 07:36:58] detectron2.evaluation.evaluator INFO: Inference done 2074/2292. 0.0672 s / img. ETA=0:00:14
[08/06 07:37:03] detectron2.evaluation.evaluator INFO: Inference done 2148/2292. 0.0672 s / img. ETA=0:00:09
[08/06 07:37:08] detectron2.evaluation.evaluator INFO: Inference done 2222/2292. 0.0672 s / img. ETA=0:00:04
[08/06 07:37:13] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:37.026277 (0.068660 s / img per device, on 4 devices)
[08/06 07:37:13] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.067218 s / img per device, on 4 devices)
[08/06 07:40:53] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:40:53] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:40:54] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:40:54] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:40:54] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 07:41:01] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0667 s / img. ETA=0:02:33
[08/06 07:41:06] detectron2.evaluation.evaluator INFO: Inference done 86/2292. 0.0662 s / img. ETA=0:02:28
[08/06 07:41:11] detectron2.evaluation.evaluator INFO: Inference done 161/2292. 0.0662 s / img. ETA=0:02:23
[08/06 07:41:16] detectron2.evaluation.evaluator INFO: Inference done 235/2292. 0.0662 s / img. ETA=0:02:18
[08/06 07:41:21] detectron2.evaluation.evaluator INFO: Inference done 309/2292. 0.0663 s / img. ETA=0:02:13
[08/06 07:41:26] detectron2.evaluation.evaluator INFO: Inference done 383/2292. 0.0665 s / img. ETA=0:02:09
[08/06 07:41:31] detectron2.evaluation.evaluator INFO: Inference done 457/2292. 0.0666 s / img. ETA=0:02:04
[08/06 07:41:36] detectron2.evaluation.evaluator INFO: Inference done 531/2292. 0.0667 s / img. ETA=0:01:59
[08/06 07:41:41] detectron2.evaluation.evaluator INFO: Inference done 605/2292. 0.0667 s / img. ETA=0:01:54
[08/06 07:41:46] detectron2.evaluation.evaluator INFO: Inference done 679/2292. 0.0667 s / img. ETA=0:01:49
[08/06 07:41:52] detectron2.evaluation.evaluator INFO: Inference done 753/2292. 0.0668 s / img. ETA=0:01:44
[08/06 07:41:57] detectron2.evaluation.evaluator INFO: Inference done 827/2292. 0.0668 s / img. ETA=0:01:39
[08/06 07:42:02] detectron2.evaluation.evaluator INFO: Inference done 901/2292. 0.0668 s / img. ETA=0:01:34
[08/06 07:42:07] detectron2.evaluation.evaluator INFO: Inference done 975/2292. 0.0668 s / img. ETA=0:01:29
[08/06 07:42:12] detectron2.evaluation.evaluator INFO: Inference done 1049/2292. 0.0668 s / img. ETA=0:01:24
[08/06 07:42:17] detectron2.evaluation.evaluator INFO: Inference done 1123/2292. 0.0669 s / img. ETA=0:01:19
[08/06 07:42:22] detectron2.evaluation.evaluator INFO: Inference done 1196/2292. 0.0669 s / img. ETA=0:01:14
[08/06 07:42:27] detectron2.evaluation.evaluator INFO: Inference done 1270/2292. 0.0669 s / img. ETA=0:01:09
[08/06 07:42:32] detectron2.evaluation.evaluator INFO: Inference done 1344/2292. 0.0669 s / img. ETA=0:01:04
[08/06 07:42:37] detectron2.evaluation.evaluator INFO: Inference done 1418/2292. 0.0669 s / img. ETA=0:00:59
[08/06 07:42:42] detectron2.evaluation.evaluator INFO: Inference done 1492/2292. 0.0669 s / img. ETA=0:00:54
[08/06 07:42:47] detectron2.evaluation.evaluator INFO: Inference done 1566/2292. 0.0669 s / img. ETA=0:00:49
[08/06 07:42:52] detectron2.evaluation.evaluator INFO: Inference done 1640/2292. 0.0669 s / img. ETA=0:00:44
[08/06 07:42:57] detectron2.evaluation.evaluator INFO: Inference done 1711/2292. 0.0670 s / img. ETA=0:00:39
[08/06 07:43:02] detectron2.evaluation.evaluator INFO: Inference done 1785/2292. 0.0670 s / img. ETA=0:00:34
[08/06 07:43:07] detectron2.evaluation.evaluator INFO: Inference done 1858/2292. 0.0670 s / img. ETA=0:00:29
[08/06 07:43:12] detectron2.evaluation.evaluator INFO: Inference done 1932/2292. 0.0670 s / img. ETA=0:00:24
[08/06 07:43:17] detectron2.evaluation.evaluator INFO: Inference done 2005/2292. 0.0670 s / img. ETA=0:00:19
[08/06 07:43:22] detectron2.evaluation.evaluator INFO: Inference done 2079/2292. 0.0670 s / img. ETA=0:00:14
[08/06 07:43:27] detectron2.evaluation.evaluator INFO: Inference done 2153/2292. 0.0670 s / img. ETA=0:00:09
[08/06 07:43:32] detectron2.evaluation.evaluator INFO: Inference done 2227/2292. 0.0670 s / img. ETA=0:00:04
[08/06 07:43:37] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:36.394234 (0.068384 s / img per device, on 4 devices)
[08/06 07:43:37] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.067016 s / img per device, on 4 devices)
[08/06 07:47:16] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:47:16] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:47:17] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:47:17] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:47:17] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 07:47:24] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0671 s / img. ETA=0:02:35
[08/06 07:47:29] detectron2.evaluation.evaluator INFO: Inference done 85/2292. 0.0664 s / img. ETA=0:02:29
[08/06 07:47:34] detectron2.evaluation.evaluator INFO: Inference done 159/2292. 0.0664 s / img. ETA=0:02:24
[08/06 07:47:39] detectron2.evaluation.evaluator INFO: Inference done 233/2292. 0.0665 s / img. ETA=0:02:19
[08/06 07:47:44] detectron2.evaluation.evaluator INFO: Inference done 307/2292. 0.0665 s / img. ETA=0:02:14
[08/06 07:47:49] detectron2.evaluation.evaluator INFO: Inference done 381/2292. 0.0666 s / img. ETA=0:02:09
[08/06 07:47:54] detectron2.evaluation.evaluator INFO: Inference done 455/2292. 0.0667 s / img. ETA=0:02:04
[08/06 07:47:59] detectron2.evaluation.evaluator INFO: Inference done 528/2292. 0.0668 s / img. ETA=0:02:00
[08/06 07:48:04] detectron2.evaluation.evaluator INFO: Inference done 600/2292. 0.0670 s / img. ETA=0:01:55
[08/06 07:48:09] detectron2.evaluation.evaluator INFO: Inference done 674/2292. 0.0670 s / img. ETA=0:01:50
[08/06 07:48:14] detectron2.evaluation.evaluator INFO: Inference done 746/2292. 0.0671 s / img. ETA=0:01:45
[08/06 07:48:20] detectron2.evaluation.evaluator INFO: Inference done 817/2292. 0.0674 s / img. ETA=0:01:41
[08/06 07:48:25] detectron2.evaluation.evaluator INFO: Inference done 891/2292. 0.0674 s / img. ETA=0:01:36
[08/06 07:48:30] detectron2.evaluation.evaluator INFO: Inference done 965/2292. 0.0673 s / img. ETA=0:01:31
[08/06 07:48:35] detectron2.evaluation.evaluator INFO: Inference done 1039/2292. 0.0673 s / img. ETA=0:01:25
[08/06 07:48:40] detectron2.evaluation.evaluator INFO: Inference done 1113/2292. 0.0673 s / img. ETA=0:01:20
[08/06 07:48:45] detectron2.evaluation.evaluator INFO: Inference done 1187/2292. 0.0673 s / img. ETA=0:01:15
[08/06 07:48:50] detectron2.evaluation.evaluator INFO: Inference done 1259/2292. 0.0674 s / img. ETA=0:01:10
[08/06 07:48:55] detectron2.evaluation.evaluator INFO: Inference done 1329/2292. 0.0675 s / img. ETA=0:01:06
[08/06 07:49:00] detectron2.evaluation.evaluator INFO: Inference done 1400/2292. 0.0676 s / img. ETA=0:01:01
[08/06 07:49:05] detectron2.evaluation.evaluator INFO: Inference done 1473/2292. 0.0676 s / img. ETA=0:00:56
[08/06 07:49:10] detectron2.evaluation.evaluator INFO: Inference done 1547/2292. 0.0676 s / img. ETA=0:00:51
[08/06 07:49:15] detectron2.evaluation.evaluator INFO: Inference done 1621/2292. 0.0675 s / img. ETA=0:00:46
[08/06 07:49:20] detectron2.evaluation.evaluator INFO: Inference done 1693/2292. 0.0676 s / img. ETA=0:00:41
[08/06 07:49:25] detectron2.evaluation.evaluator INFO: Inference done 1767/2292. 0.0676 s / img. ETA=0:00:36
[08/06 07:49:30] detectron2.evaluation.evaluator INFO: Inference done 1841/2292. 0.0675 s / img. ETA=0:00:31
[08/06 07:49:35] detectron2.evaluation.evaluator INFO: Inference done 1915/2292. 0.0675 s / img. ETA=0:00:25
[08/06 07:49:40] detectron2.evaluation.evaluator INFO: Inference done 1989/2292. 0.0675 s / img. ETA=0:00:20
[08/06 07:49:45] detectron2.evaluation.evaluator INFO: Inference done 2063/2292. 0.0675 s / img. ETA=0:00:15
[08/06 07:49:50] detectron2.evaluation.evaluator INFO: Inference done 2137/2292. 0.0675 s / img. ETA=0:00:10
[08/06 07:49:55] detectron2.evaluation.evaluator INFO: Inference done 2211/2292. 0.0674 s / img. ETA=0:00:05
[08/06 07:50:01] detectron2.evaluation.evaluator INFO: Inference done 2284/2292. 0.0675 s / img. ETA=0:00:00
[08/06 07:50:01] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:37.578434 (0.068902 s / img per device, on 4 devices)
[08/06 07:50:01] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:34 (0.067456 s / img per device, on 4 devices)
[08/06 07:53:38] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 07:53:38] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 07:53:38] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 07:53:38] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 07:53:38] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 07:53:46] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0659 s / img. ETA=0:02:32
[08/06 07:53:51] detectron2.evaluation.evaluator INFO: Inference done 86/2292. 0.0663 s / img. ETA=0:02:28
[08/06 07:53:56] detectron2.evaluation.evaluator INFO: Inference done 161/2292. 0.0663 s / img. ETA=0:02:23
[08/06 07:54:01] detectron2.evaluation.evaluator INFO: Inference done 235/2292. 0.0663 s / img. ETA=0:02:19
[08/06 07:54:06] detectron2.evaluation.evaluator INFO: Inference done 309/2292. 0.0664 s / img. ETA=0:02:14
[08/06 07:54:11] detectron2.evaluation.evaluator INFO: Inference done 383/2292. 0.0664 s / img. ETA=0:02:09
[08/06 07:54:16] detectron2.evaluation.evaluator INFO: Inference done 457/2292. 0.0665 s / img. ETA=0:02:04
[08/06 07:54:21] detectron2.evaluation.evaluator INFO: Inference done 529/2292. 0.0668 s / img. ETA=0:01:59
[08/06 07:54:26] detectron2.evaluation.evaluator INFO: Inference done 602/2292. 0.0669 s / img. ETA=0:01:55
[08/06 07:54:31] detectron2.evaluation.evaluator INFO: Inference done 676/2292. 0.0669 s / img. ETA=0:01:50
[08/06 07:54:36] detectron2.evaluation.evaluator INFO: Inference done 750/2292. 0.0669 s / img. ETA=0:01:45
[08/06 07:54:41] detectron2.evaluation.evaluator INFO: Inference done 824/2292. 0.0669 s / img. ETA=0:01:40
[08/06 07:54:46] detectron2.evaluation.evaluator INFO: Inference done 897/2292. 0.0669 s / img. ETA=0:01:35
[08/06 07:54:51] detectron2.evaluation.evaluator INFO: Inference done 971/2292. 0.0669 s / img. ETA=0:01:30
[08/06 07:54:56] detectron2.evaluation.evaluator INFO: Inference done 1045/2292. 0.0669 s / img. ETA=0:01:25
[08/06 07:55:01] detectron2.evaluation.evaluator INFO: Inference done 1119/2292. 0.0669 s / img. ETA=0:01:19
[08/06 07:55:06] detectron2.evaluation.evaluator INFO: Inference done 1193/2292. 0.0669 s / img. ETA=0:01:14
[08/06 07:55:11] detectron2.evaluation.evaluator INFO: Inference done 1267/2292. 0.0669 s / img. ETA=0:01:09
[08/06 07:55:16] detectron2.evaluation.evaluator INFO: Inference done 1341/2292. 0.0669 s / img. ETA=0:01:04
[08/06 07:55:22] detectron2.evaluation.evaluator INFO: Inference done 1415/2292. 0.0669 s / img. ETA=0:00:59
[08/06 07:55:27] detectron2.evaluation.evaluator INFO: Inference done 1489/2292. 0.0669 s / img. ETA=0:00:54
[08/06 07:55:32] detectron2.evaluation.evaluator INFO: Inference done 1563/2292. 0.0669 s / img. ETA=0:00:49
[08/06 07:55:37] detectron2.evaluation.evaluator INFO: Inference done 1637/2292. 0.0669 s / img. ETA=0:00:44
[08/06 07:55:42] detectron2.evaluation.evaluator INFO: Inference done 1711/2292. 0.0669 s / img. ETA=0:00:39
[08/06 07:55:47] detectron2.evaluation.evaluator INFO: Inference done 1785/2292. 0.0669 s / img. ETA=0:00:34
[08/06 07:55:52] detectron2.evaluation.evaluator INFO: Inference done 1859/2292. 0.0669 s / img. ETA=0:00:29
[08/06 07:55:57] detectron2.evaluation.evaluator INFO: Inference done 1933/2292. 0.0669 s / img. ETA=0:00:24
[08/06 07:56:02] detectron2.evaluation.evaluator INFO: Inference done 2007/2292. 0.0669 s / img. ETA=0:00:19
[08/06 07:56:07] detectron2.evaluation.evaluator INFO: Inference done 2081/2292. 0.0669 s / img. ETA=0:00:14
[08/06 07:56:12] detectron2.evaluation.evaluator INFO: Inference done 2155/2292. 0.0669 s / img. ETA=0:00:09
[08/06 07:56:17] detectron2.evaluation.evaluator INFO: Inference done 2229/2292. 0.0669 s / img. ETA=0:00:04
[08/06 07:56:22] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:36.320019 (0.068352 s / img per device, on 4 devices)
[08/06 07:56:22] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.066947 s / img per device, on 4 devices)
[08/06 07:59:59] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 08:00:00] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 08:00:00] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 08:00:00] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 08:00:00] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 08:00:07] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0660 s / img. ETA=0:02:32
[08/06 08:00:12] detectron2.evaluation.evaluator INFO: Inference done 85/2292. 0.0665 s / img. ETA=0:02:29
[08/06 08:00:17] detectron2.evaluation.evaluator INFO: Inference done 159/2292. 0.0665 s / img. ETA=0:02:24
[08/06 08:00:22] detectron2.evaluation.evaluator INFO: Inference done 233/2292. 0.0665 s / img. ETA=0:02:19
[08/06 08:00:27] detectron2.evaluation.evaluator INFO: Inference done 307/2292. 0.0665 s / img. ETA=0:02:14
[08/06 08:00:32] detectron2.evaluation.evaluator INFO: Inference done 381/2292. 0.0666 s / img. ETA=0:02:09
[08/06 08:00:38] detectron2.evaluation.evaluator INFO: Inference done 455/2292. 0.0667 s / img. ETA=0:02:04
[08/06 08:00:43] detectron2.evaluation.evaluator INFO: Inference done 529/2292. 0.0667 s / img. ETA=0:01:59
[08/06 08:00:48] detectron2.evaluation.evaluator INFO: Inference done 602/2292. 0.0668 s / img. ETA=0:01:55
[08/06 08:00:53] detectron2.evaluation.evaluator INFO: Inference done 676/2292. 0.0668 s / img. ETA=0:01:49
[08/06 08:00:58] detectron2.evaluation.evaluator INFO: Inference done 750/2292. 0.0668 s / img. ETA=0:01:45
[08/06 08:01:03] detectron2.evaluation.evaluator INFO: Inference done 824/2292. 0.0668 s / img. ETA=0:01:39
[08/06 08:01:08] detectron2.evaluation.evaluator INFO: Inference done 898/2292. 0.0668 s / img. ETA=0:01:34
[08/06 08:01:13] detectron2.evaluation.evaluator INFO: Inference done 972/2292. 0.0669 s / img. ETA=0:01:29
[08/06 08:01:18] detectron2.evaluation.evaluator INFO: Inference done 1046/2292. 0.0669 s / img. ETA=0:01:24
[08/06 08:01:23] detectron2.evaluation.evaluator INFO: Inference done 1120/2292. 0.0669 s / img. ETA=0:01:19
[08/06 08:01:28] detectron2.evaluation.evaluator INFO: Inference done 1194/2292. 0.0669 s / img. ETA=0:01:14
[08/06 08:01:33] detectron2.evaluation.evaluator INFO: Inference done 1268/2292. 0.0669 s / img. ETA=0:01:09
[08/06 08:01:38] detectron2.evaluation.evaluator INFO: Inference done 1342/2292. 0.0669 s / img. ETA=0:01:04
[08/06 08:01:43] detectron2.evaluation.evaluator INFO: Inference done 1416/2292. 0.0669 s / img. ETA=0:00:59
[08/06 08:01:48] detectron2.evaluation.evaluator INFO: Inference done 1490/2292. 0.0669 s / img. ETA=0:00:54
[08/06 08:01:53] detectron2.evaluation.evaluator INFO: Inference done 1564/2292. 0.0669 s / img. ETA=0:00:49
[08/06 08:01:58] detectron2.evaluation.evaluator INFO: Inference done 1638/2292. 0.0669 s / img. ETA=0:00:44
[08/06 08:02:03] detectron2.evaluation.evaluator INFO: Inference done 1712/2292. 0.0669 s / img. ETA=0:00:39
[08/06 08:02:08] detectron2.evaluation.evaluator INFO: Inference done 1786/2292. 0.0669 s / img. ETA=0:00:34
[08/06 08:02:13] detectron2.evaluation.evaluator INFO: Inference done 1860/2292. 0.0669 s / img. ETA=0:00:29
[08/06 08:02:18] detectron2.evaluation.evaluator INFO: Inference done 1934/2292. 0.0669 s / img. ETA=0:00:24
[08/06 08:02:24] detectron2.evaluation.evaluator INFO: Inference done 2008/2292. 0.0669 s / img. ETA=0:00:19
[08/06 08:02:29] detectron2.evaluation.evaluator INFO: Inference done 2082/2292. 0.0669 s / img. ETA=0:00:14
[08/06 08:02:34] detectron2.evaluation.evaluator INFO: Inference done 2156/2292. 0.0669 s / img. ETA=0:00:09
[08/06 08:02:39] detectron2.evaluation.evaluator INFO: Inference done 2230/2292. 0.0669 s / img. ETA=0:00:04
[08/06 08:02:43] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:36.258439 (0.068325 s / img per device, on 4 devices)
[08/06 08:02:43] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.066933 s / img per device, on 4 devices)
[08/06 08:03:15] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 221, in run_step
    self._write_metrics(metrics_dict)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 256, in _write_metrics
    all_metrics_dict = comm.gather(metrics_dict)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/utils/comm.py", line 200, in gather
    size_list, tensor = _pad_to_largest_tensor(tensor, group)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/utils/comm.py", line 126, in _pad_to_largest_tensor
    dist.all_gather(size_list, local_size, group=group)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1192, in all_gather
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1595629395347/work/third_party/gloo/gloo/transport/tcp/pair.cc:575] Connection closed by peer [127.0.1.1]:52635
[08/06 08:03:15] detectron2.engine.hooks INFO: Overall training speed: 5110 iterations in 0:17:55 (0.2104 s / it)
[08/06 08:03:15] detectron2.engine.hooks INFO: Total training time: 0:32:14 (0:14:19 on hooks)
[08/06 08:16:12] detectron2 INFO: Rank of current process: 1. World size: 4
[08/06 08:16:13] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 08:16:13] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '4', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 08:16:13] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 08:16:13] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 08:16:14] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 08:16:16] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 08:16:16] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 08:16:16] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 08:16:18] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 08:16:18] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 08:16:18] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 08:16:18] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 08:16:18] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 08:16:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0024999.pth ...
[08/06 08:16:19] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0024999.pth ...
[08/06 08:16:19] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0024999.pth ...
[08/06 08:16:19] detectron2.engine.train_loop INFO: Starting training from iteration 25000
[08/06 08:19:50] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 08:19:50] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 08:19:50] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 08:19:51] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 08:19:51] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 08:19:58] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0655 s / img. ETA=0:02:31
[08/06 08:20:03] detectron2.evaluation.evaluator INFO: Inference done 85/2292. 0.0663 s / img. ETA=0:02:29
[08/06 08:20:08] detectron2.evaluation.evaluator INFO: Inference done 159/2292. 0.0663 s / img. ETA=0:02:24
[08/06 08:20:13] detectron2.evaluation.evaluator INFO: Inference done 233/2292. 0.0663 s / img. ETA=0:02:19
[08/06 08:20:18] detectron2.evaluation.evaluator INFO: Inference done 307/2292. 0.0665 s / img. ETA=0:02:14
[08/06 08:20:23] detectron2.evaluation.evaluator INFO: Inference done 381/2292. 0.0666 s / img. ETA=0:02:09
[08/06 08:20:28] detectron2.evaluation.evaluator INFO: Inference done 455/2292. 0.0667 s / img. ETA=0:02:04
[08/06 08:20:33] detectron2.evaluation.evaluator INFO: Inference done 528/2292. 0.0668 s / img. ETA=0:02:00
[08/06 08:20:38] detectron2.evaluation.evaluator INFO: Inference done 602/2292. 0.0668 s / img. ETA=0:01:55
[08/06 08:20:43] detectron2.evaluation.evaluator INFO: Inference done 676/2292. 0.0668 s / img. ETA=0:01:50
[08/06 08:20:48] detectron2.evaluation.evaluator INFO: Inference done 750/2292. 0.0668 s / img. ETA=0:01:44
[08/06 08:20:53] detectron2.evaluation.evaluator INFO: Inference done 824/2292. 0.0669 s / img. ETA=0:01:39
[08/06 08:20:59] detectron2.evaluation.evaluator INFO: Inference done 898/2292. 0.0669 s / img. ETA=0:01:34
[08/06 08:21:04] detectron2.evaluation.evaluator INFO: Inference done 972/2292. 0.0669 s / img. ETA=0:01:29
[08/06 08:21:09] detectron2.evaluation.evaluator INFO: Inference done 1046/2292. 0.0669 s / img. ETA=0:01:24
[08/06 08:21:14] detectron2.evaluation.evaluator INFO: Inference done 1120/2292. 0.0669 s / img. ETA=0:01:19
[08/06 08:21:19] detectron2.evaluation.evaluator INFO: Inference done 1194/2292. 0.0669 s / img. ETA=0:01:14
[08/06 08:21:24] detectron2.evaluation.evaluator INFO: Inference done 1268/2292. 0.0669 s / img. ETA=0:01:09
[08/06 08:21:29] detectron2.evaluation.evaluator INFO: Inference done 1342/2292. 0.0669 s / img. ETA=0:01:04
[08/06 08:21:34] detectron2.evaluation.evaluator INFO: Inference done 1416/2292. 0.0669 s / img. ETA=0:00:59
[08/06 08:21:39] detectron2.evaluation.evaluator INFO: Inference done 1490/2292. 0.0669 s / img. ETA=0:00:54
[08/06 08:21:44] detectron2.evaluation.evaluator INFO: Inference done 1564/2292. 0.0669 s / img. ETA=0:00:49
[08/06 08:21:49] detectron2.evaluation.evaluator INFO: Inference done 1638/2292. 0.0669 s / img. ETA=0:00:44
[08/06 08:21:54] detectron2.evaluation.evaluator INFO: Inference done 1712/2292. 0.0669 s / img. ETA=0:00:39
[08/06 08:21:59] detectron2.evaluation.evaluator INFO: Inference done 1786/2292. 0.0669 s / img. ETA=0:00:34
[08/06 08:22:04] detectron2.evaluation.evaluator INFO: Inference done 1860/2292. 0.0669 s / img. ETA=0:00:29
[08/06 08:22:09] detectron2.evaluation.evaluator INFO: Inference done 1934/2292. 0.0669 s / img. ETA=0:00:24
[08/06 08:22:14] detectron2.evaluation.evaluator INFO: Inference done 2008/2292. 0.0669 s / img. ETA=0:00:19
[08/06 08:22:19] detectron2.evaluation.evaluator INFO: Inference done 2082/2292. 0.0669 s / img. ETA=0:00:14
[08/06 08:22:24] detectron2.evaluation.evaluator INFO: Inference done 2156/2292. 0.0669 s / img. ETA=0:00:09
[08/06 08:22:29] detectron2.evaluation.evaluator INFO: Inference done 2230/2292. 0.0669 s / img. ETA=0:00:04
[08/06 08:22:34] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:36.233419 (0.068314 s / img per device, on 4 devices)
[08/06 08:22:34] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.066944 s / img per device, on 4 devices)
[08/06 08:22:43] detectron2.engine.hooks INFO: Overall training speed: 1014 iterations in 0:03:26 (0.2033 s / it)
[08/06 08:22:43] detectron2.engine.hooks INFO: Total training time: 0:06:16 (0:02:49 on hooks)
[08/06 08:29:02] detectron2 INFO: Rank of current process: 1. World size: 4
[08/06 08:29:03] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 08:29:03] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 08:29:03] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 08:29:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 08:29:03] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 08:29:06] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 08:29:06] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 08:29:06] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 08:29:07] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 08:29:07] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 08:29:08] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 08:29:08] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 08:29:08] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 08:29:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0025999.pth ...
[08/06 08:29:08] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0025999.pth ...
[08/06 08:29:08] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0025999.pth ...
[08/06 08:29:08] detectron2.engine.train_loop INFO: Starting training from iteration 26000
[08/06 08:39:56] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 08:39:56] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 08:39:57] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 08:39:57] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 08:39:57] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 08:40:04] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0667 s / img. ETA=0:02:34
[08/06 08:40:09] detectron2.evaluation.evaluator INFO: Inference done 86/2292. 0.0662 s / img. ETA=0:02:28
[08/06 08:40:14] detectron2.evaluation.evaluator INFO: Inference done 161/2292. 0.0661 s / img. ETA=0:02:23
[08/06 08:40:19] detectron2.evaluation.evaluator INFO: Inference done 235/2292. 0.0662 s / img. ETA=0:02:18
[08/06 08:40:24] detectron2.evaluation.evaluator INFO: Inference done 309/2292. 0.0663 s / img. ETA=0:02:13
[08/06 08:40:29] detectron2.evaluation.evaluator INFO: Inference done 383/2292. 0.0665 s / img. ETA=0:02:09
[08/06 08:40:34] detectron2.evaluation.evaluator INFO: Inference done 452/2292. 0.0666 s / img. ETA=0:02:06
[08/06 08:40:40] detectron2.evaluation.evaluator INFO: Inference done 525/2292. 0.0668 s / img. ETA=0:02:01
[08/06 08:40:45] detectron2.evaluation.evaluator INFO: Inference done 599/2292. 0.0668 s / img. ETA=0:01:56
[08/06 08:40:50] detectron2.evaluation.evaluator INFO: Inference done 673/2292. 0.0668 s / img. ETA=0:01:51
[08/06 08:40:55] detectron2.evaluation.evaluator INFO: Inference done 747/2292. 0.0669 s / img. ETA=0:01:45
[08/06 08:41:00] detectron2.evaluation.evaluator INFO: Inference done 821/2292. 0.0669 s / img. ETA=0:01:40
[08/06 08:41:05] detectron2.evaluation.evaluator INFO: Inference done 895/2292. 0.0669 s / img. ETA=0:01:35
[08/06 08:41:10] detectron2.evaluation.evaluator INFO: Inference done 969/2292. 0.0669 s / img. ETA=0:01:30
[08/06 08:41:15] detectron2.evaluation.evaluator INFO: Inference done 1043/2292. 0.0669 s / img. ETA=0:01:25
[08/06 08:41:20] detectron2.evaluation.evaluator INFO: Inference done 1117/2292. 0.0669 s / img. ETA=0:01:20
[08/06 08:41:25] detectron2.evaluation.evaluator INFO: Inference done 1191/2292. 0.0669 s / img. ETA=0:01:15
[08/06 08:41:30] detectron2.evaluation.evaluator INFO: Inference done 1265/2292. 0.0669 s / img. ETA=0:01:10
[08/06 08:41:35] detectron2.evaluation.evaluator INFO: Inference done 1339/2292. 0.0669 s / img. ETA=0:01:05
[08/06 08:41:40] detectron2.evaluation.evaluator INFO: Inference done 1412/2292. 0.0669 s / img. ETA=0:01:00
[08/06 08:41:45] detectron2.evaluation.evaluator INFO: Inference done 1486/2292. 0.0669 s / img. ETA=0:00:55
[08/06 08:41:50] detectron2.evaluation.evaluator INFO: Inference done 1560/2292. 0.0669 s / img. ETA=0:00:50
[08/06 08:41:55] detectron2.evaluation.evaluator INFO: Inference done 1634/2292. 0.0669 s / img. ETA=0:00:45
[08/06 08:42:00] detectron2.evaluation.evaluator INFO: Inference done 1708/2292. 0.0669 s / img. ETA=0:00:39
[08/06 08:42:05] detectron2.evaluation.evaluator INFO: Inference done 1782/2292. 0.0669 s / img. ETA=0:00:34
[08/06 08:42:10] detectron2.evaluation.evaluator INFO: Inference done 1856/2292. 0.0669 s / img. ETA=0:00:29
[08/06 08:42:15] detectron2.evaluation.evaluator INFO: Inference done 1930/2292. 0.0669 s / img. ETA=0:00:24
[08/06 08:42:21] detectron2.evaluation.evaluator INFO: Inference done 2004/2292. 0.0669 s / img. ETA=0:00:19
[08/06 08:42:26] detectron2.evaluation.evaluator INFO: Inference done 2078/2292. 0.0669 s / img. ETA=0:00:14
[08/06 08:42:31] detectron2.evaluation.evaluator INFO: Inference done 2152/2292. 0.0669 s / img. ETA=0:00:09
[08/06 08:42:36] detectron2.evaluation.evaluator INFO: Inference done 2226/2292. 0.0669 s / img. ETA=0:00:04
[08/06 08:42:40] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:36.591436 (0.068470 s / img per device, on 4 devices)
[08/06 08:42:40] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.066946 s / img per device, on 4 devices)
[08/06 08:45:42] detectron2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 221, in run_step
    self._write_metrics(metrics_dict)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/engine/train_loop.py", line 256, in _write_metrics
    all_metrics_dict = comm.gather(metrics_dict)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/utils/comm.py", line 200, in gather
    size_list, tensor = _pad_to_largest_tensor(tensor, group)
  File "/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2/utils/comm.py", line 126, in _pad_to_largest_tensor
    dist.all_gather(size_list, local_size, group=group)
  File "/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1192, in all_gather
    work.wait()
RuntimeError: [/opt/conda/conda-bld/pytorch_1595629395347/work/third_party/gloo/gloo/transport/tcp/pair.cc:575] Connection closed by peer [127.0.0.1]:13478
[08/06 08:45:42] detectron2.engine.hooks INFO: Overall training speed: 1276 iterations in 0:13:36 (0.6396 s / it)
[08/06 08:45:42] detectron2.engine.hooks INFO: Total training time: 0:16:24 (0:02:48 on hooks)
[08/06 08:57:55] detectron2 INFO: Rank of current process: 1. World size: 4
[08/06 08:57:56] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 08:57:56] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 08:57:56] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 08:57:56] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 08:57:57] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 08:57:59] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 08:58:00] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 08:58:00] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 08:58:01] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 08:58:01] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 08:58:01] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 08:58:01] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 08:58:01] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 08:58:01] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0026999.pth ...
[08/06 08:58:02] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0026999.pth ...
[08/06 08:58:02] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0026999.pth ...
[08/06 08:58:02] detectron2.engine.train_loop INFO: Starting training from iteration 27000
[08/06 09:08:49] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 09:08:50] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 09:08:50] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 09:08:50] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 09:08:50] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 09:08:58] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0665 s / img. ETA=0:02:33
[08/06 09:09:03] detectron2.evaluation.evaluator INFO: Inference done 85/2292. 0.0664 s / img. ETA=0:02:29
[08/06 09:09:08] detectron2.evaluation.evaluator INFO: Inference done 159/2292. 0.0664 s / img. ETA=0:02:24
[08/06 09:09:13] detectron2.evaluation.evaluator INFO: Inference done 233/2292. 0.0664 s / img. ETA=0:02:19
[08/06 09:09:18] detectron2.evaluation.evaluator INFO: Inference done 307/2292. 0.0665 s / img. ETA=0:02:14
[08/06 09:09:23] detectron2.evaluation.evaluator INFO: Inference done 381/2292. 0.0666 s / img. ETA=0:02:09
[08/06 09:09:28] detectron2.evaluation.evaluator INFO: Inference done 455/2292. 0.0667 s / img. ETA=0:02:04
[08/06 09:09:33] detectron2.evaluation.evaluator INFO: Inference done 529/2292. 0.0667 s / img. ETA=0:01:59
[08/06 09:09:38] detectron2.evaluation.evaluator INFO: Inference done 603/2292. 0.0668 s / img. ETA=0:01:54
[08/06 09:09:43] detectron2.evaluation.evaluator INFO: Inference done 677/2292. 0.0668 s / img. ETA=0:01:49
[08/06 09:09:48] detectron2.evaluation.evaluator INFO: Inference done 750/2292. 0.0668 s / img. ETA=0:01:44
[08/06 09:09:53] detectron2.evaluation.evaluator INFO: Inference done 824/2292. 0.0668 s / img. ETA=0:01:39
[08/06 09:09:58] detectron2.evaluation.evaluator INFO: Inference done 898/2292. 0.0668 s / img. ETA=0:01:34
[08/06 09:10:03] detectron2.evaluation.evaluator INFO: Inference done 972/2292. 0.0669 s / img. ETA=0:01:29
[08/06 09:10:08] detectron2.evaluation.evaluator INFO: Inference done 1046/2292. 0.0669 s / img. ETA=0:01:24
[08/06 09:10:13] detectron2.evaluation.evaluator INFO: Inference done 1120/2292. 0.0669 s / img. ETA=0:01:19
[08/06 09:10:18] detectron2.evaluation.evaluator INFO: Inference done 1194/2292. 0.0669 s / img. ETA=0:01:14
[08/06 09:10:23] detectron2.evaluation.evaluator INFO: Inference done 1268/2292. 0.0669 s / img. ETA=0:01:09
[08/06 09:10:28] detectron2.evaluation.evaluator INFO: Inference done 1342/2292. 0.0669 s / img. ETA=0:01:04
[08/06 09:10:34] detectron2.evaluation.evaluator INFO: Inference done 1416/2292. 0.0669 s / img. ETA=0:00:59
[08/06 09:10:39] detectron2.evaluation.evaluator INFO: Inference done 1490/2292. 0.0669 s / img. ETA=0:00:54
[08/06 09:10:44] detectron2.evaluation.evaluator INFO: Inference done 1563/2292. 0.0669 s / img. ETA=0:00:49
[08/06 09:10:49] detectron2.evaluation.evaluator INFO: Inference done 1637/2292. 0.0669 s / img. ETA=0:00:44
[08/06 09:10:54] detectron2.evaluation.evaluator INFO: Inference done 1711/2292. 0.0669 s / img. ETA=0:00:39
[08/06 09:10:59] detectron2.evaluation.evaluator INFO: Inference done 1785/2292. 0.0669 s / img. ETA=0:00:34
[08/06 09:11:04] detectron2.evaluation.evaluator INFO: Inference done 1858/2292. 0.0669 s / img. ETA=0:00:29
[08/06 09:11:09] detectron2.evaluation.evaluator INFO: Inference done 1932/2292. 0.0670 s / img. ETA=0:00:24
[08/06 09:11:14] detectron2.evaluation.evaluator INFO: Inference done 2006/2292. 0.0670 s / img. ETA=0:00:19
[08/06 09:11:19] detectron2.evaluation.evaluator INFO: Inference done 2080/2292. 0.0670 s / img. ETA=0:00:14
[08/06 09:11:24] detectron2.evaluation.evaluator INFO: Inference done 2154/2292. 0.0670 s / img. ETA=0:00:09
[08/06 09:11:29] detectron2.evaluation.evaluator INFO: Inference done 2228/2292. 0.0670 s / img. ETA=0:00:04
[08/06 09:11:34] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:36.296218 (0.068341 s / img per device, on 4 devices)
[08/06 09:11:34] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.066955 s / img per device, on 4 devices)
[08/06 09:13:02] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 09:13:02] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 09:13:02] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 09:13:03] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 09:13:03] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 09:13:10] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0665 s / img. ETA=0:02:33
[08/06 09:13:15] detectron2.evaluation.evaluator INFO: Inference done 86/2292. 0.0661 s / img. ETA=0:02:28
[08/06 09:13:20] detectron2.evaluation.evaluator INFO: Inference done 161/2292. 0.0661 s / img. ETA=0:02:23
[08/06 09:13:25] detectron2.evaluation.evaluator INFO: Inference done 236/2292. 0.0662 s / img. ETA=0:02:18
[08/06 09:13:30] detectron2.evaluation.evaluator INFO: Inference done 311/2292. 0.0662 s / img. ETA=0:02:13
[08/06 09:13:35] detectron2.evaluation.evaluator INFO: Inference done 385/2292. 0.0663 s / img. ETA=0:02:08
[08/06 09:13:41] detectron2.evaluation.evaluator INFO: Inference done 459/2292. 0.0665 s / img. ETA=0:02:04
[08/06 09:13:46] detectron2.evaluation.evaluator INFO: Inference done 533/2292. 0.0665 s / img. ETA=0:01:59
[08/06 09:13:51] detectron2.evaluation.evaluator INFO: Inference done 607/2292. 0.0666 s / img. ETA=0:01:54
[08/06 09:13:56] detectron2.evaluation.evaluator INFO: Inference done 681/2292. 0.0666 s / img. ETA=0:01:49
[08/06 09:14:01] detectron2.evaluation.evaluator INFO: Inference done 755/2292. 0.0667 s / img. ETA=0:01:44
[08/06 09:14:06] detectron2.evaluation.evaluator INFO: Inference done 829/2292. 0.0667 s / img. ETA=0:01:39
[08/06 09:14:11] detectron2.evaluation.evaluator INFO: Inference done 903/2292. 0.0667 s / img. ETA=0:01:34
[08/06 09:14:16] detectron2.evaluation.evaluator INFO: Inference done 977/2292. 0.0668 s / img. ETA=0:01:29
[08/06 09:14:21] detectron2.evaluation.evaluator INFO: Inference done 1051/2292. 0.0668 s / img. ETA=0:01:24
[08/06 09:14:26] detectron2.evaluation.evaluator INFO: Inference done 1125/2292. 0.0668 s / img. ETA=0:01:19
[08/06 09:14:31] detectron2.evaluation.evaluator INFO: Inference done 1199/2292. 0.0668 s / img. ETA=0:01:14
[08/06 09:14:36] detectron2.evaluation.evaluator INFO: Inference done 1273/2292. 0.0668 s / img. ETA=0:01:09
[08/06 09:14:41] detectron2.evaluation.evaluator INFO: Inference done 1347/2292. 0.0668 s / img. ETA=0:01:04
[08/06 09:14:46] detectron2.evaluation.evaluator INFO: Inference done 1421/2292. 0.0668 s / img. ETA=0:00:59
[08/06 09:14:51] detectron2.evaluation.evaluator INFO: Inference done 1495/2292. 0.0669 s / img. ETA=0:00:54
[08/06 09:14:56] detectron2.evaluation.evaluator INFO: Inference done 1569/2292. 0.0669 s / img. ETA=0:00:49
[08/06 09:15:01] detectron2.evaluation.evaluator INFO: Inference done 1643/2292. 0.0669 s / img. ETA=0:00:44
[08/06 09:15:06] detectron2.evaluation.evaluator INFO: Inference done 1717/2292. 0.0669 s / img. ETA=0:00:39
[08/06 09:15:11] detectron2.evaluation.evaluator INFO: Inference done 1791/2292. 0.0669 s / img. ETA=0:00:34
[08/06 09:15:16] detectron2.evaluation.evaluator INFO: Inference done 1865/2292. 0.0669 s / img. ETA=0:00:29
[08/06 09:15:22] detectron2.evaluation.evaluator INFO: Inference done 1939/2292. 0.0669 s / img. ETA=0:00:24
[08/06 09:15:27] detectron2.evaluation.evaluator INFO: Inference done 2013/2292. 0.0669 s / img. ETA=0:00:19
[08/06 09:15:32] detectron2.evaluation.evaluator INFO: Inference done 2086/2292. 0.0669 s / img. ETA=0:00:14
[08/06 09:15:37] detectron2.evaluation.evaluator INFO: Inference done 2159/2292. 0.0669 s / img. ETA=0:00:09
[08/06 09:15:42] detectron2.evaluation.evaluator INFO: Inference done 2233/2292. 0.0669 s / img. ETA=0:00:04
[08/06 09:15:46] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:36.190858 (0.068295 s / img per device, on 4 devices)
[08/06 09:15:46] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:33 (0.066937 s / img per device, on 4 devices)
[08/06 09:15:52] detectron2.engine.hooks INFO: Overall training speed: 1122 iterations in 0:11:58 (0.6404 s / it)
[08/06 09:15:52] detectron2.engine.hooks INFO: Total training time: 0:17:41 (0:05:43 on hooks)
[08/06 09:26:13] detectron2 INFO: Rank of current process: 1. World size: 4
[08/06 09:26:13] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 09:26:13] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', 'datasets/noh_nms_model_final.pth'], resume=False)
[08/06 09:26:13] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 09:26:13] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: datasets/noh_nms_model_final.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 09:26:14] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 09:26:16] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 09:26:17] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 09:26:17] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 09:26:18] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 09:26:18] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 09:26:18] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 09:26:18] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 09:26:18] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 09:26:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_final.pth ...
[08/06 09:26:19] fvcore.common.checkpoint INFO: Loading optimizer from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_final.pth ...
[08/06 09:26:19] fvcore.common.checkpoint INFO: Loading scheduler from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_final.pth ...
[08/06 09:26:19] detectron2.engine.train_loop INFO: Starting training from iteration 28125
[08/06 09:26:19] detectron2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[08/06 09:28:16] detectron2 INFO: Rank of current process: 1. World size: 4
[08/06 09:28:17] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 09:28:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', './Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth'], resume=False)
[08/06 09:28:17] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 09:28:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 09:28:17] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 09:28:19] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 09:28:20] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 09:28:20] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 09:28:21] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 09:28:21] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 09:28:22] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 09:28:22] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 09:28:22] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 09:28:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth ...
[08/06 09:28:22] detectron2.engine.train_loop INFO: Starting training from iteration 28000
[08/06 09:29:48] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 09:29:48] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 09:29:49] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 09:29:49] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 09:29:49] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 09:29:56] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0657 s / img. ETA=0:02:31
[08/06 09:30:01] detectron2.evaluation.evaluator INFO: Inference done 86/2292. 0.0660 s / img. ETA=0:02:28
[08/06 09:30:06] detectron2.evaluation.evaluator INFO: Inference done 161/2292. 0.0659 s / img. ETA=0:02:23
[08/06 09:30:11] detectron2.evaluation.evaluator INFO: Inference done 236/2292. 0.0660 s / img. ETA=0:02:18
[08/06 09:30:16] detectron2.evaluation.evaluator INFO: Inference done 311/2292. 0.0661 s / img. ETA=0:02:13
[08/06 09:30:21] detectron2.evaluation.evaluator INFO: Inference done 385/2292. 0.0661 s / img. ETA=0:02:08
[08/06 09:30:26] detectron2.evaluation.evaluator INFO: Inference done 460/2292. 0.0661 s / img. ETA=0:02:03
[08/06 09:30:31] detectron2.evaluation.evaluator INFO: Inference done 534/2292. 0.0662 s / img. ETA=0:01:58
[08/06 09:30:37] detectron2.evaluation.evaluator INFO: Inference done 609/2292. 0.0662 s / img. ETA=0:01:53
[08/06 09:30:42] detectron2.evaluation.evaluator INFO: Inference done 683/2292. 0.0662 s / img. ETA=0:01:48
[08/06 09:30:47] detectron2.evaluation.evaluator INFO: Inference done 757/2292. 0.0662 s / img. ETA=0:01:43
[08/06 09:30:52] detectron2.evaluation.evaluator INFO: Inference done 831/2292. 0.0663 s / img. ETA=0:01:38
[08/06 09:30:57] detectron2.evaluation.evaluator INFO: Inference done 905/2292. 0.0664 s / img. ETA=0:01:33
[08/06 09:31:02] detectron2.evaluation.evaluator INFO: Inference done 979/2292. 0.0664 s / img. ETA=0:01:28
[08/06 09:31:07] detectron2.evaluation.evaluator INFO: Inference done 1053/2292. 0.0665 s / img. ETA=0:01:23
[08/06 09:31:12] detectron2.evaluation.evaluator INFO: Inference done 1127/2292. 0.0665 s / img. ETA=0:01:18
[08/06 09:31:17] detectron2.evaluation.evaluator INFO: Inference done 1201/2292. 0.0665 s / img. ETA=0:01:13
[08/06 09:31:22] detectron2.evaluation.evaluator INFO: Inference done 1275/2292. 0.0666 s / img. ETA=0:01:08
[08/06 09:31:27] detectron2.evaluation.evaluator INFO: Inference done 1349/2292. 0.0666 s / img. ETA=0:01:03
[08/06 09:31:32] detectron2.evaluation.evaluator INFO: Inference done 1423/2292. 0.0666 s / img. ETA=0:00:58
[08/06 09:31:37] detectron2.evaluation.evaluator INFO: Inference done 1497/2292. 0.0666 s / img. ETA=0:00:53
[08/06 09:31:42] detectron2.evaluation.evaluator INFO: Inference done 1571/2292. 0.0666 s / img. ETA=0:00:48
[08/06 09:31:47] detectron2.evaluation.evaluator INFO: Inference done 1645/2292. 0.0667 s / img. ETA=0:00:43
[08/06 09:31:52] detectron2.evaluation.evaluator INFO: Inference done 1719/2292. 0.0667 s / img. ETA=0:00:38
[08/06 09:31:57] detectron2.evaluation.evaluator INFO: Inference done 1793/2292. 0.0667 s / img. ETA=0:00:33
[08/06 09:32:02] detectron2.evaluation.evaluator INFO: Inference done 1867/2292. 0.0667 s / img. ETA=0:00:28
[08/06 09:32:07] detectron2.evaluation.evaluator INFO: Inference done 1941/2292. 0.0667 s / img. ETA=0:00:23
[08/06 09:32:12] detectron2.evaluation.evaluator INFO: Inference done 2015/2292. 0.0667 s / img. ETA=0:00:18
[08/06 09:32:18] detectron2.evaluation.evaluator INFO: Inference done 2089/2292. 0.0667 s / img. ETA=0:00:13
[08/06 09:32:23] detectron2.evaluation.evaluator INFO: Inference done 2163/2292. 0.0667 s / img. ETA=0:00:08
[08/06 09:32:28] detectron2.evaluation.evaluator INFO: Inference done 2237/2292. 0.0668 s / img. ETA=0:00:03
[08/06 09:32:32] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:35.810939 (0.068129 s / img per device, on 4 devices)
[08/06 09:32:32] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:32 (0.066756 s / img per device, on 4 devices)
[08/06 09:32:38] detectron2.engine.hooks INFO: Overall training speed: 122 iterations in 0:01:16 (0.6290 s / it)
[08/06 09:32:38] detectron2.engine.hooks INFO: Total training time: 0:04:06 (0:02:50 on hooks)
[08/06 20:56:35] detectron2 INFO: Rank of current process: 1. World size: 4
[08/06 20:56:35] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.8.11 (default, Aug  3 2021, 15:09:35) [GCC 7.5.0]
numpy                     1.20.3
detectron2                0.1.1 @/hd1/lqurszh/Documents/ai_workspace/PedestrianDetection-NohNMS/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  10.2
detectron2 arch flags     sm_61
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.6.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0,1,2,3               GeForce GTX 1080 Ti
CUDA_HOME                 /usr/local/cuda
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    8.3.1
torchvision               0.7.0 @/hd1/lqurszh/anaconda3/envs/torch16-py38/lib/python3.8/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.5.2
------------------------  ---------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.3-Product Build 20210617 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[08/06 20:56:35] detectron2 INFO: Command line arguments: Namespace(config_file='configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml', dist_url='tcp://127.0.0.1:56648', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=['SOLVER.IMS_PER_BATCH', '16', 'SOLVER.BASE_LR', '0.0025', 'SOLVER.CHECKPOINT_PERIOD', '500', 'MODEL.WEIGHTS', './Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth'], resume=False)
[08/06 20:56:35] detectron2 INFO: Contents of args.config_file=configs/Ped/faster_rcnn_R_50_FPN_baseline_iou_0.5_noh_nms.yaml:
_BASE_: "./faster_rcnn_R_50_FPN_baseline_iou_0.5.yaml"
MODEL:
  OVERLAP_BOX_HEAD:
    ENABLE: True
    BUILD_ON_ROI_FEATURE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    REG_LOSS_COEFF: 1.0
    UNIFORM_REG_DIVISOR: True
    PROB_LOSS_BETA: 0.02
# OUTPUT_DIR: "/data/workspace/Experiments/detectron2/Crowdhuman/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"
OUTPUT_DIR: "./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms"

[08/06 20:56:35] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('ped_val',)
  TRAIN: ('ped_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1400
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ALLOW_BOX_OUT_OF_BOUNDARY: True
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[1.0, 2.0, 3.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone_better
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: BN
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  OVERLAP_BOX_HEAD:
    BUILD_ON_ROI_FEATURE: True
    ENABLE: True
    OVERLAP_IOU_THRESHOLD: 0.4
    PROB_LOSS_BETA: 0.02
    REG_LOSS_COEFF: 1.0
    SIGMOID_ON: True
    UNIFORM_REG_DIVISOR: True
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CLS_NUM_CONV: 0
    CLS_NUM_FC: 0
    CONV_DIM: 256
    FC_DIM: 1024
    GIoU: False
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    REG_NUM_CONV: 0
    REG_NUM_FC: 0
    SMOOTH_L1_BETA: 1.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IGNORE_IOA: True
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    GET_GT_PER_LEVEL: True
    HEAD_NAME: StandardRPNHead
    IGNORE_AMBIGUOUS_SAMPLE: False
    IGNORE_IOA: False
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 1.0
    TOP_PROPOSALS_ALL_LEVEL: True
    UPDATE_MATCHES: True
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth
OUTPUT_DIR: ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms
SEED: 11301414
SOLVER:
  BASE_LR: 0.0025
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 500
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 28125
  MOMENTUM: 0.9
  STEPS: (18750, 24375)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 800
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 200
  EVAL_PERIOD: 1000
  EVAL_START: 12000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[08/06 20:56:36] detectron2.engine.defaults INFO: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelAvgPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1)
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
    (overlap_head): FastRCNNConvFCHead(
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (overlap_predictor): OverlapOutputLayers(
      (overlap_prob): Linear(in_features=1024, out_features=1, bias=True)
      (overlap_pred): Linear(in_features=1024, out_features=4, bias=True)
    )
  )
)
[08/06 20:56:38] detectron2.data.datasets.ped INFO: Loaded 36100 images in Ped from datasets/ped/annotations/train.json
[08/06 20:56:39] detectron2.data.datasets.ped INFO: Loaded 200517 instances and 200517 ignore instances in CrowdHuman from datasets/ped/annotations/train.json
[08/06 20:56:39] detectron2.data.build INFO: Removed 8 images with no usable annotations. 36092 images left.
[08/06 20:56:40] detectron2.data.build INFO: Distribution of instances among all 2 categories:
[36m|  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|
|    ped     | 0            |    ign     | 0            |
|            |              |            |              |
|   total    | 0            |            |              |[0m
[08/06 20:56:40] detectron2.data.common INFO: Serializing 36092 elements to byte tensors and concatenating them all ...
[08/06 20:56:40] detectron2.data.common INFO: Serialized dataset takes 18.89 MiB
[08/06 20:56:40] detectron2.data.detection_utils INFO: TransformGens used in training: [ResizeShortestEdge(short_edge_length=(800,), max_size=1400, sample_style='choice'), RandomFlip()]
[08/06 20:56:40] detectron2.data.build INFO: Using training sampler TrainingSampler
[08/06 20:56:41] fvcore.common.checkpoint INFO: [Checkpointer] Loading from ./Experiments/detectron2/Ped/faster_rcnn_R_50_FPN_baseline_iou0.5_noh_nms/model_0027999.pth ...
[08/06 20:56:41] detectron2.engine.train_loop INFO: Starting training from iteration 28000
[08/06 20:58:05] detectron2.data.datasets.ped INFO: Loaded 9166 images in Ped from datasets/ped/annotations/val.json
[08/06 20:58:06] detectron2.data.datasets.ped INFO: Loaded 51174 instances and 51174 ignore instances in CrowdHuman from datasets/ped/annotations/val.json
[08/06 20:58:06] detectron2.data.common INFO: Serializing 9166 elements to byte tensors and concatenating them all ...
[08/06 20:58:06] detectron2.data.common INFO: Serialized dataset takes 4.81 MiB
[08/06 20:58:06] detectron2.evaluation.evaluator INFO: Start inference on 2292 images
[08/06 20:58:14] detectron2.evaluation.evaluator INFO: Inference done 11/2292. 0.0660 s / img. ETA=0:02:33
[08/06 20:58:19] detectron2.evaluation.evaluator INFO: Inference done 86/2292. 0.0660 s / img. ETA=0:02:28
[08/06 20:58:24] detectron2.evaluation.evaluator INFO: Inference done 161/2292. 0.0660 s / img. ETA=0:02:23
[08/06 20:58:29] detectron2.evaluation.evaluator INFO: Inference done 236/2292. 0.0660 s / img. ETA=0:02:18
[08/06 20:58:34] detectron2.evaluation.evaluator INFO: Inference done 310/2292. 0.0661 s / img. ETA=0:02:13
[08/06 20:58:39] detectron2.evaluation.evaluator INFO: Inference done 385/2292. 0.0661 s / img. ETA=0:02:08
[08/06 20:58:44] detectron2.evaluation.evaluator INFO: Inference done 459/2292. 0.0662 s / img. ETA=0:02:03
[08/06 20:58:49] detectron2.evaluation.evaluator INFO: Inference done 533/2292. 0.0662 s / img. ETA=0:01:58
[08/06 20:58:54] detectron2.evaluation.evaluator INFO: Inference done 607/2292. 0.0662 s / img. ETA=0:01:53
[08/06 20:58:59] detectron2.evaluation.evaluator INFO: Inference done 681/2292. 0.0663 s / img. ETA=0:01:48
[08/06 20:59:04] detectron2.evaluation.evaluator INFO: Inference done 755/2292. 0.0663 s / img. ETA=0:01:43
[08/06 20:59:09] detectron2.evaluation.evaluator INFO: Inference done 829/2292. 0.0664 s / img. ETA=0:01:39
[08/06 20:59:14] detectron2.evaluation.evaluator INFO: Inference done 903/2292. 0.0665 s / img. ETA=0:01:34
[08/06 20:59:19] detectron2.evaluation.evaluator INFO: Inference done 977/2292. 0.0665 s / img. ETA=0:01:29
[08/06 20:59:24] detectron2.evaluation.evaluator INFO: Inference done 1051/2292. 0.0665 s / img. ETA=0:01:24
[08/06 20:59:29] detectron2.evaluation.evaluator INFO: Inference done 1125/2292. 0.0666 s / img. ETA=0:01:19
[08/06 20:59:34] detectron2.evaluation.evaluator INFO: Inference done 1199/2292. 0.0666 s / img. ETA=0:01:14
[08/06 20:59:39] detectron2.evaluation.evaluator INFO: Inference done 1273/2292. 0.0666 s / img. ETA=0:01:09
[08/06 20:59:44] detectron2.evaluation.evaluator INFO: Inference done 1347/2292. 0.0666 s / img. ETA=0:01:04
[08/06 20:59:49] detectron2.evaluation.evaluator INFO: Inference done 1421/2292. 0.0666 s / img. ETA=0:00:59
[08/06 20:59:54] detectron2.evaluation.evaluator INFO: Inference done 1495/2292. 0.0667 s / img. ETA=0:00:54
[08/06 21:00:00] detectron2.evaluation.evaluator INFO: Inference done 1569/2292. 0.0667 s / img. ETA=0:00:49
[08/06 21:00:05] detectron2.evaluation.evaluator INFO: Inference done 1643/2292. 0.0667 s / img. ETA=0:00:44
[08/06 21:00:10] detectron2.evaluation.evaluator INFO: Inference done 1717/2292. 0.0667 s / img. ETA=0:00:39
[08/06 21:00:15] detectron2.evaluation.evaluator INFO: Inference done 1791/2292. 0.0667 s / img. ETA=0:00:34
[08/06 21:00:20] detectron2.evaluation.evaluator INFO: Inference done 1865/2292. 0.0667 s / img. ETA=0:00:29
[08/06 21:00:25] detectron2.evaluation.evaluator INFO: Inference done 1939/2292. 0.0667 s / img. ETA=0:00:24
[08/06 21:00:30] detectron2.evaluation.evaluator INFO: Inference done 2013/2292. 0.0667 s / img. ETA=0:00:18
[08/06 21:00:35] detectron2.evaluation.evaluator INFO: Inference done 2087/2292. 0.0667 s / img. ETA=0:00:13
[08/06 21:00:40] detectron2.evaluation.evaluator INFO: Inference done 2161/2292. 0.0668 s / img. ETA=0:00:08
[08/06 21:00:45] detectron2.evaluation.evaluator INFO: Inference done 2235/2292. 0.0668 s / img. ETA=0:00:03
[08/06 21:00:49] detectron2.evaluation.evaluator INFO: Total inference time: 0:02:35.892849 (0.068165 s / img per device, on 4 devices)
[08/06 21:00:49] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:02:32 (0.066762 s / img per device, on 4 devices)
[08/06 21:00:55] detectron2.engine.hooks INFO: Overall training speed: 122 iterations in 0:01:15 (0.6168 s / it)
[08/06 21:00:55] detectron2.engine.hooks INFO: Total training time: 0:04:05 (0:02:50 on hooks)
